commit 13bd817bb88499ce1dc1dfdaffcde17fa492aca5
Author: Aneesh Kumar K.V <aneesh.kumar@linux.vnet.ibm.com>
Date:   Mon May 11 11:56:01 2015 +0530

    powerpc/thp: Serialize pmd clear against a linux page table walk.
    
    Serialize against find_linux_pte_or_hugepte() which does lock-less
    lookup in page tables with local interrupts disabled. For huge pages it
    casts pmd_t to pte_t. Since the format of pte_t is different from pmd_t
    we want to prevent transit from pmd pointing to page table to pmd
    pointing to huge page (and back) while interrupts are disabled.  We
    clear pmd to possibly replace it with page table pointer in different
    code paths. So make sure we wait for the parallel
    find_linux_pte_or_hugepage() to finish.
    
    Without this patch, a find_linux_pte_or_hugepte() running in parallel to
    __split_huge_zero_page_pmd() or do_huge_pmd_wp_page_fallback() or
    zap_huge_pmd() can run into the above issue. With
    __split_huge_zero_page_pmd() and do_huge_pmd_wp_page_fallback() we clear
    the hugepage pte before inserting the pmd entry with a regular pgtable
    address. Such a clear need to wait for the parallel
    find_linux_pte_or_hugepte() to finish.
    
    With zap_huge_pmd(), we can run into issues, with a hugepage pte getting
    zapped due to a MADV_DONTNEED while other cpu fault it in as small
    pages.
    
    Reported-by: Kirill A. Shutemov <kirill.shutemov@linux.intel.com>
    Signed-off-by: Aneesh Kumar K.V <aneesh.kumar@linux.vnet.ibm.com>
    Reviewed-by: Kirill A. Shutemov <kirill.shutemov@linux.intel.com>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/mm/pgtable_64.c b/arch/powerpc/mm/pgtable_64.c
index 59daa5eeec25..6bfadf1aa5cb 100644
--- a/arch/powerpc/mm/pgtable_64.c
+++ b/arch/powerpc/mm/pgtable_64.c
@@ -839,6 +839,17 @@ pmd_t pmdp_get_and_clear(struct mm_struct *mm,
 	 * hash fault look at them.
 	 */
 	memset(pgtable, 0, PTE_FRAG_SIZE);
+	/*
+	 * Serialize against find_linux_pte_or_hugepte which does lock-less
+	 * lookup in page tables with local interrupts disabled. For huge pages
+	 * it casts pmd_t to pte_t. Since format of pte_t is different from
+	 * pmd_t we want to prevent transit from pmd pointing to page table
+	 * to pmd pointing to huge page (and back) while interrupts are disabled.
+	 * We clear pmd to possibly replace it with page table pointer in
+	 * different code paths. So make sure we wait for the parallel
+	 * find_linux_pte_or_hugepage to finish.
+	 */
+	kick_all_cpus_sync();
 	return old_pmd;
 }
 

