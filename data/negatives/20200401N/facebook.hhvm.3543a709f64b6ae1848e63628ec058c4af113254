commit 3543a709f64b6ae1848e63628ec058c4af113254
Author: Edwin Smith <smith@fb.com>
Date:   Sat Sep 27 14:02:25 2014 -0700

    Remove XLS, Constraint, and related dead code
    
    Reviewed By: @alexmalyshev
    
    Differential Revision: D1582745

diff --git a/hphp/runtime/vm/jit/back-end-arm.cpp b/hphp/runtime/vm/jit/back-end-arm.cpp
index 3efab4889c..c7451f0870 100644
--- a/hphp/runtime/vm/jit/back-end-arm.cpp
+++ b/hphp/runtime/vm/jit/back-end-arm.cpp
@@ -68,17 +68,6 @@ struct BackEnd : public jit::BackEnd {
     return PhysReg(arm::rVmFp);
   }
 
-  Constraint srcConstraint(const IRInstruction& inst, unsigned i) override {
-    return arm::srcConstraint(inst, i);
-  }
-
-  Constraint dstConstraint(const IRInstruction& inst, unsigned i) override {
-    return arm::dstConstraint(inst, i);
-  }
-
-  RegPair precolorSrc(const IRInstruction& inst, unsigned i) override;
-  RegPair precolorDst(const IRInstruction& inst, unsigned i) override;
-
   bool storesCell(const IRInstruction& inst, uint32_t srcIdx) override {
     return false;
   }
@@ -173,14 +162,6 @@ struct BackEnd : public jit::BackEnd {
     info.stubAddr = reinterpret_cast<TCA>(sim.xreg(arm::rAsm.code()));
   }
 
-  jit::CodeGenerator* newCodeGenerator(const IRUnit& unit,
-                                       CodeBlock& mainCode,
-                                       CodeBlock& coldCode,
-                                       CodeBlock& frozenCode,
-                                       CodegenState& state) override {
-    always_assert(false);
-  }
-
   void moveToAlign(CodeBlock& cb,
                    MoveToAlignFlags alignment
                    = MoveToAlignFlags::kJmpTargetAlign) override {
@@ -250,34 +231,6 @@ struct BackEnd : public jit::BackEnd {
     // TODO(2967396) implement properly
   }
 
-  void emitFwdJmp(CodeBlock& cb, Block* target, CodegenState& state) override {
-    // This function always emits a smashable jump but every jump on ARM is
-    // smashable so it's free.
-    emitJumpToBlock(cb, target, CC_None, state);
-  }
-
-  void patchJumps(CodeBlock& cb, CodegenState& state, Block* block) override {
-    auto dest = cb.frontier();
-    auto jump = reinterpret_cast<TCA>(state.patches[block]);
-
-    while (jump && jump != kEndOfTargetChain) {
-      auto nextIfJmp = jmpTarget(jump);
-      auto nextIfJcc = jccTarget(jump);
-
-      // Exactly one of them must be non-nullptr
-      assert(!(nextIfJmp && nextIfJcc));
-      assert(nextIfJmp || nextIfJcc);
-
-      if (nextIfJmp) {
-        smashJmp(jump, dest);
-        jump = nextIfJmp;
-      } else {
-        smashJcc(jump, dest);
-        jump = nextIfJcc;
-      }
-    }
-  }
-
   bool isSmashable(Address frontier, int nBytes, int offset = 0) override {
     // See prepareForSmash().
     return true;
@@ -515,14 +468,6 @@ std::unique_ptr<jit::BackEnd> newBackEnd() {
   return std::unique_ptr<jit::BackEnd>{ folly::make_unique<BackEnd>() };
 }
 
-RegPair BackEnd::precolorSrc(const IRInstruction& inst, unsigned i) {
-  return InvalidRegPair;
-}
-
-RegPair BackEnd::precolorDst(const IRInstruction& inst, unsigned i) {
-  return InvalidRegPair;
-}
-
 static size_t genBlock(IRUnit& unit, Vout& v, Vasm& vasm,
                        CodegenState& state, Block* block) {
   FTRACE(6, "genBlock: {}\n", block->id());
@@ -545,9 +490,7 @@ static size_t genBlock(IRUnit& unit, Vout& v, Vasm& vasm,
 
 void BackEnd::genCodeImpl(IRUnit& unit, AsmInfo* asmInfo) {
   Timer _t(Timer::codeGen);
-  RegAllocInfo no_regs(unit);
-  LiveRegs no_live_regs(unit, RegSet());
-  CodegenState state(unit, no_regs, no_live_regs, asmInfo);
+  CodegenState state(unit, asmInfo);
 
   CodeBlock& mainCodeIn   = mcg->code.main();
   CodeBlock& coldCodeIn   = mcg->code.cold();
diff --git a/hphp/runtime/vm/jit/back-end-x64.cpp b/hphp/runtime/vm/jit/back-end-x64.cpp
index 09726773a1..3dc392bf5a 100644
--- a/hphp/runtime/vm/jit/back-end-x64.cpp
+++ b/hphp/runtime/vm/jit/back-end-x64.cpp
@@ -77,14 +77,6 @@ struct BackEnd : public jit::BackEnd {
     return x64::rVmFp;
   }
 
-  Constraint srcConstraint(const IRInstruction& inst, unsigned i) override {
-    return x64::srcConstraint(inst, i);
-  }
-
-  Constraint dstConstraint(const IRInstruction& inst, unsigned i) override {
-    return x64::dstConstraint(inst, i);
-  }
-
   bool storesCell(const IRInstruction& inst, uint32_t srcIdx) override {
     return x64::storesCell(inst, srcIdx);
   }
@@ -93,9 +85,6 @@ struct BackEnd : public jit::BackEnd {
     return x64::loadsCell(inst.op());
   }
 
-  RegPair precolorSrc(const IRInstruction& inst, unsigned i) override;
-  RegPair precolorDst(const IRInstruction& inst, unsigned i) override;
-
   /*
    * enterTCHelper does not save callee-saved registers except %rbp. This means
    * when we call it from C++, we have to tell gcc to clobber all the other
@@ -126,14 +115,6 @@ struct BackEnd : public jit::BackEnd {
     CALLEE_SAVED_BARRIER();
   }
 
-  jit::CodeGenerator* newCodeGenerator(const IRUnit& unit,
-                                       CodeBlock& mainCode,
-                                       CodeBlock& coldCode,
-                                       CodeBlock& frozenCode,
-                                       CodegenState& state) override {
-    always_assert(false);
-  }
-
   void moveToAlign(CodeBlock& cb,
                    MoveToAlignFlags alignment
                    = MoveToAlignFlags::kJmpTargetAlign) override {
@@ -210,14 +191,6 @@ struct BackEnd : public jit::BackEnd {
     x64::emitTraceCall(cb, pcOff);
   }
 
-  void emitFwdJmp(CodeBlock& cb, Block* target, CodegenState& state) override {
-    always_assert(false);
-  }
-
-  void patchJumps(CodeBlock& cb, CodegenState& state, Block* block) override {
-    always_assert(false);
-  }
-
   bool isSmashable(Address frontier, int nBytes, int offset = 0) override {
     assert(nBytes <= int(kCacheLineSize));
     uintptr_t iFrontier = uintptr_t(frontier) + offset;
@@ -713,165 +686,12 @@ std::unique_ptr<jit::BackEnd> newBackEnd() {
   return folly::make_unique<BackEnd>();
 }
 
-using NativeCalls::CallMap;
-using NativeCalls::Arg;
-using NativeCalls::ArgType;
-
-// return the number of registers needed to pass this arg
-int argSize(const Arg& arg, const IRInstruction& inst) {
-  switch (arg.type) {
-    case ArgType::SSA:
-    case ArgType::Imm:
-    case ArgType::ExtraImm:
-      return 1;
-    case ArgType::TV:
-      return 2;
-    case ArgType::MemberKeyS:
-      return inst.src(arg.ival)->isA(Type::Str) ? 1 : 2;
-    case ArgType::MemberKeyIS:
-      return inst.src(arg.ival)->isA(Type::Str) ? 1 :
-             inst.src(arg.ival)->isA(Type::Int) ? 1 : 2;
-  }
-  return 1;
-}
-
-// Return the argument-register hint for a native-call opcode.
-RegPair hintNativeCallSrc(const IRInstruction& inst, unsigned i) {
-  auto const& args = CallMap::info(inst.op()).args;
-  auto pos = 0;
-  for (auto& arg : args) {
-    if (argSize(arg, inst) == 1) {
-      if (arg.ival == i && pos < kNumRegisterArgs) {
-        return {argNumToRegName[pos], InvalidReg};
-      }
-      pos++;
-    } else {
-      if (arg.ival == i && pos + 1 < kNumRegisterArgs) {
-        return {argNumToRegName[pos], argNumToRegName[pos + 1]};
-      }
-      pos += 2;
-    }
-  }
-  return InvalidRegPair;
-}
-
-// return the return-value register hint for a NativeCall opcode.
-RegPair hintNativeCallDst(const IRInstruction& inst, unsigned i) {
-  if (i != 0) return InvalidRegPair;
-  auto const& info = CallMap::info(inst.op());
-  switch (info.dest) {
-    case DestType::SSA:
-      return {rax, InvalidReg};
-    case DestType::Dbl:
-    case DestType::SIMD:
-      return {xmm0, InvalidReg};
-    case DestType::TV:
-      return {rax, rdx};
-    case DestType::None:
-      return InvalidRegPair;
-  }
-  return InvalidRegPair;
-}
-
-// Return the arg-register hint for a CallBuiltin instruction.
-RegPair hintCallBuiltinSrc(const IRInstruction& inst, unsigned srcNum) {
-  auto callee = inst.extra<CallBuiltin>()->callee;
-  auto ipos = 0, dpos = 0, spos = 0;
-  if (isCppByRef(callee->returnType())) {
-    if (srcNum == 0) {
-      return {argNumToRegName[0], InvalidReg};
-    }
-    ipos = spos = 1;
-  }
-  // Iterate through the builtin params, keeping track of the HHIR src
-  // pos (spos) and the corresponding int (ipos) and double (dpos)
-  // register argument positions.  When spos == srcNum, return a hint.
-  auto& params = callee->params();
-  int i = 0, n = callee->numParams();
-  for (; i < n && spos < srcNum; ++i, ++spos) {
-    if (params[i].builtinType == KindOfDouble) {
-      dpos++;
-    } else {
-      ipos++;
-    }
-  }
-  if (i < n && spos == srcNum) {
-    if (params[i].builtinType == KindOfDouble) {
-      if (dpos < kNumSIMDRegisterArgs) {
-        return {argNumToSIMDRegName[dpos], InvalidReg};
-      }
-    } else {
-      if (ipos < kNumRegisterArgs) {
-        return {argNumToRegName[ipos], InvalidReg};
-      }
-    }
-  }
-  return InvalidRegPair;
-}
-
-// return the return-register hint for a CallBuiltin instruction
-RegPair hintCallBuiltinDst(const IRInstruction& inst, unsigned i) {
-  // the decision logic here is distilled from CodeGenerator::cgCallBuiltin()
-  if (!RuntimeOption::EvalHHIREnablePreColoring) return InvalidRegPair;
-  if (i != 0) return InvalidRegPair;
-  auto returnType = inst.typeParam();
-  if (returnType <= Type::Dbl) {
-    return {xmm0, InvalidReg};
-  }
-  if (returnType.isSimpleType()) {
-    return {rax, InvalidReg};
-  }
-  // other return types are passed via stack; generated code reloads
-  // them, so using the ABI assigned registers doesn't matter.
-  return InvalidRegPair;
-}
-
-RegPair BackEnd::precolorSrc(const IRInstruction& inst, unsigned i) {
-  if (!RuntimeOption::EvalHHIREnablePreColoring) return InvalidRegPair;
-  if (CallMap::hasInfo(inst.op())) {
-    return hintNativeCallSrc(inst, i);
-  }
-  switch (inst.op()) {
-    case CallBuiltin:
-      return hintCallBuiltinSrc(inst, i);
-    case Shl:
-    case Shr:
-      if (i == 1) return {PhysReg(rcx), InvalidReg};
-      break;
-    case Mod:
-      // x86 idiv does: rdx:rax/r => quotent:rax, remainder:rdx
-      if (i == 0) return {PhysReg(rax), InvalidReg};
-    default:
-      break;
-  }
-  return InvalidRegPair;
-}
-
-RegPair BackEnd::precolorDst(const IRInstruction& inst, unsigned i) {
-  if (!RuntimeOption::EvalHHIREnablePreColoring) return InvalidRegPair;
-  if (CallMap::hasInfo(inst.op())) {
-    return hintNativeCallDst(inst, i);
-  }
-  switch (inst.op()) {
-    case CallBuiltin:
-      return hintCallBuiltinDst(inst, i);
-    case Mod:
-      // x86 idiv does: rdx:rax/r => quotent:rax, remainder:rdx
-      if (i == 0) return {PhysReg(rdx), InvalidReg};
-      break;
-    default:
-      break;
-  }
-  return InvalidRegPair;
-}
-
 static size_t genBlock(IRUnit& unit, Vout& v, Vasm& vasm,
                        CodegenState& state, Block* block) {
   FTRACE(6, "genBlock: {}\n", block->id());
   CodeGenerator cg(unit, v, vasm.cold(), vasm.frozen(), state);
   size_t hhir_count{0};
   for (IRInstruction& instr : *block) {
-    if (instr.op() == Shuffle) continue;
     IRInstruction* inst = &instr;
     hhir_count++;
 
@@ -898,9 +718,7 @@ UNUSED const Abi vasm_abi {
 
 void BackEnd::genCodeImpl(IRUnit& unit, AsmInfo* asmInfo) {
   Timer _t(Timer::codeGen);
-  RegAllocInfo no_regs(unit);
-  LiveRegs no_live_regs(unit, RegSet());
-  CodegenState state(unit, no_regs, no_live_regs, asmInfo);
+  CodegenState state(unit, asmInfo);
 
   CodeBlock& mainCodeIn   = mcg->code.main();
   CodeBlock& coldCodeIn   = mcg->code.cold();
diff --git a/hphp/runtime/vm/jit/back-end.h b/hphp/runtime/vm/jit/back-end.h
index a0677f43db..7f9f905dde 100644
--- a/hphp/runtime/vm/jit/back-end.h
+++ b/hphp/runtime/vm/jit/back-end.h
@@ -93,19 +93,10 @@ class BackEnd {
   virtual PhysReg rSp() = 0;
   virtual PhysReg rVmSp() = 0;
   virtual PhysReg rVmFp() = 0;
-  virtual Constraint srcConstraint(const IRInstruction& inst, unsigned i) = 0;
-  virtual Constraint dstConstraint(const IRInstruction& inst, unsigned i) = 0;
-  virtual RegPair precolorSrc(const IRInstruction& inst, unsigned i) = 0;
-  virtual RegPair precolorDst(const IRInstruction& inst, unsigned i) = 0;
   virtual bool storesCell(const IRInstruction& inst, uint32_t srcIdx) = 0;
   virtual bool loadsCell(const IRInstruction& inst) = 0;
 
   virtual void enterTCHelper(TCA start, TReqInfo& info) = 0;
-  virtual CodeGenerator* newCodeGenerator(const IRUnit& unit,
-                                          CodeBlock& mainCode,
-                                          CodeBlock& coldCode,
-                                          CodeBlock& frozenCode,
-                                          CodegenState& state) = 0;
   virtual void moveToAlign(CodeBlock& cb,
                            MoveToAlignFlags alignment
                            = MoveToAlignFlags::kJmpTargetAlign) = 0;
@@ -124,9 +115,6 @@ class BackEnd {
   virtual void funcPrologueSmashGuard(TCA prologue, const Func* func) = 0;
   virtual void emitIncStat(CodeBlock& cb, intptr_t disp, int n) = 0;
   virtual void emitTraceCall(CodeBlock& cb, Offset pcOff) = 0;
-  virtual void emitFwdJmp(CodeBlock& cb, Block* target,
-                          CodegenState& state) = 0;
-  virtual void patchJumps(CodeBlock& cb, CodegenState& state, Block* block) = 0;
   /*
    * Returns true if the given current frontier can have an nBytes-long
    * instruction written that will be smashable later.
diff --git a/hphp/runtime/vm/jit/check.cpp b/hphp/runtime/vm/jit/check.cpp
index 4ecd924ab2..8c57014307 100644
--- a/hphp/runtime/vm/jit/check.cpp
+++ b/hphp/runtime/vm/jit/check.cpp
@@ -37,37 +37,6 @@ namespace {
 
 TRACE_SET_MOD(hhir);
 
-struct RegState {
-  RegState();
-  SSATmp*& tmp(const PhysLoc&, int i);
-  void merge(const RegState& other);
-  PhysReg::Map<SSATmp*> regs;  // which tmp is in each register
-  SSATmp* slots[NumPreAllocatedSpillLocs]; // which tmp is in each spill slot
-};
-
-RegState::RegState() {
-  memset(slots, 0, sizeof(slots));
-}
-
-SSATmp*& RegState::tmp(const PhysLoc& loc, int i) {
-  if (loc.spilled()) {
-    assert(loc.slot(i) < NumPreAllocatedSpillLocs);
-    return slots[loc.slot(i)];
-  }
-  auto r = loc.reg(i);
-  assert(r != jit::InvalidReg);
-  return regs[r];
-}
-
-void RegState::merge(const RegState& other) {
-  for (auto r : regs) {
-    if (regs[r] != other.regs[r]) regs[r] = nullptr;
-  }
-  for (unsigned i = 0; i < NumPreAllocatedSpillLocs; i++) {
-    if (slots[i] != other.slots[i]) slots[i] = nullptr;
-  }
-}
-
 // Return the number of parameters required for this block
 DEBUG_ONLY static int numBlockParams(Block* b) {
   return b->empty() || b->front().op() != DefLabel ? 0 :
@@ -267,115 +236,4 @@ bool checkTmpsSpanningCalls(const IRUnit& unit) {
   return isValid;
 }
 
-bool checkNoShuffles(const IRUnit& unit) {
-  postorderWalk(unit, [] (Block* b) {
-    for (DEBUG_ONLY auto& inst : *b) assert(inst.op() != Shuffle);
-  });
-  return true;
-}
-
-/*
- * Check that each destination register or spill slot is unique,
- * and that sources have the same number or less operands than
- * destinations.
- */
-bool checkShuffle(const IRInstruction& inst, const RegAllocInfo& regs) {
-  auto n = inst.numSrcs();
-  assert(n == inst.extra<Shuffle>()->size);
-  RegSet destRegs;
-  std::bitset<NumPreAllocatedSpillLocs> destSlots;
-  auto& inst_regs = regs[inst];
-  for (uint32_t i = 0; i < n; ++i) {
-    DEBUG_ONLY auto& rs = inst_regs.src(i);
-    DEBUG_ONLY auto& rd = inst.extra<Shuffle>()->dests[i];
-    if (rd.numAllocated() == 0) continue; // dest was unused; ignore.
-    if (rd.spilled()) {
-      assert(!rs.spilled()); // no mem-mem copies
-    } else {
-      // rs could have less assigned registers/slots than rd, in these cases:
-      // - when rs is empty, because the source is a constant.
-      // - when rs has 1 register because it's untagged but rd needs 2 because
-      //   it's a more general (tagged) type, because of a phi.
-      assert(rs.numWords() <= rd.numWords());
-      assert(rs.spilled() || rs.isFullSIMD() == rd.isFullSIMD());
-    }
-    for (int j = 0; j < rd.numAllocated(); ++j) {
-      if (rd.spilled()) {
-        assert(!destSlots.test(rd.slot(j)));
-        destSlots.set(rd.slot(j));
-      } else {
-        assert(!destRegs.contains(rd.reg(j))); // no duplicate dests
-        destRegs.add(rd.reg(j));
-      }
-    }
-  }
-  return true;
-}
-
-bool checkRegisters(const IRUnit& unit, const RegAllocInfo& regs) {
-  assert(checkCfg(unit));
-  auto blocks = rpoSortCfg(unit);
-  StateVector<Block, RegState> states(unit, RegState());
-  StateVector<Block, bool> reached(unit, false);
-  for (auto* block : blocks) {
-    RegState state = states[block];
-    for (IRInstruction& inst : *block) {
-      if (inst.op() == Jmp) continue; // handled by Shuffle
-      auto& inst_regs = regs[inst];
-      for (int i = 0, n = inst.numSrcs(); i < n; ++i) {
-        auto const &rs = inst_regs.src(i);
-        if (!rs.spilled()) {
-          // hack - ignore rbx and rbp
-          if (rs.reg(0) == mcg->backEnd().rVmSp() ||
-              rs.reg(0) == mcg->backEnd().rVmFp()) {
-            continue;
-          }
-        }
-        DEBUG_ONLY auto src = inst.src(i);
-        assert(rs.numWords() == src->numWords() ||
-               (src->isConst() && rs.numWords() == 0));
-        DEBUG_ONLY auto allocated = rs.numAllocated();
-        if (allocated == 2) {
-          if (rs.spilled()) {
-            assert(rs.slot(0) != rs.slot(1));
-          } else {
-            assert(rs.reg(0) != rs.reg(1));
-          }
-        }
-        for (unsigned i = 0, n = rs.numAllocated(); i < n; ++i) {
-          assert(state.tmp(rs, i) == src);
-        }
-      }
-      auto update = [&](SSATmp* tmp, const PhysLoc& loc) {
-        for (unsigned i = 0, n = loc.numAllocated(); i < n; ++i) {
-          state.tmp(loc, i) = tmp;
-        }
-      };
-      if (inst.op() == Shuffle) {
-        checkShuffle(inst, regs);
-        for (unsigned i = 0; i < inst.numSrcs(); ++i) {
-          update(inst.src(i), inst.extra<Shuffle>()->dests[i]);
-        }
-      } else {
-        for (unsigned i = 0; i < inst.numDsts(); ++i) {
-          update(inst.dst(i), inst_regs.dst(i));
-        }
-      }
-    }
-    // State contains the PhysLoc->SSATmp reverse mappings at block end;
-    // propagate the state to succ
-    auto updateEdge = [&](Block* succ) {
-      if (!reached[succ]) {
-        states[succ] = state;
-      } else {
-        states[succ].merge(state);
-      }
-    };
-    if (auto* next = block->next()) updateEdge(next);
-    if (auto* taken = block->taken()) updateEdge(taken);
-  }
-
-  return true;
-}
-
 }}
diff --git a/hphp/runtime/vm/jit/check.h b/hphp/runtime/vm/jit/check.h
index 751107cb46..f23a0c9319 100644
--- a/hphp/runtime/vm/jit/check.h
+++ b/hphp/runtime/vm/jit/check.h
@@ -37,18 +37,6 @@ bool checkCfg(const IRUnit&);
  */
 bool checkTmpsSpanningCalls(const IRUnit&);
 
-/*
- * Make sure there's no shuffle instructions. (called right before register
- * allocation.
- */
-bool checkNoShuffles(const IRUnit&);
-
-/*
- * Check register and spill slot assignments; registers and spill slots must
- * contain the correct SSATmp value at every point of use.
- */
-bool checkRegisters(const IRUnit&, const RegAllocInfo&);
-
 }}
 
 #endif
diff --git a/hphp/runtime/vm/jit/code-gen-arm.cpp b/hphp/runtime/vm/jit/code-gen-arm.cpp
index d9e0df882c..3edce31a4e 100644
--- a/hphp/runtime/vm/jit/code-gen-arm.cpp
+++ b/hphp/runtime/vm/jit/code-gen-arm.cpp
@@ -53,7 +53,6 @@ NOOP_OPCODE(ExceptionBarrier)
 NOOP_OPCODE(TakeStack)
 NOOP_OPCODE(TakeRef)
 NOOP_OPCODE(EndGuards)
-NOOP_OPCODE(Shuffle)
 
 // XXX
 NOOP_OPCODE(DbgAssertPtr);
@@ -538,33 +537,6 @@ PUNT_OPCODE(ColIsNEmpty)
 
 //////////////////////////////////////////////////////////////////////
 
-void emitJumpToBlock(CodeBlock& cb, Block* target, ConditionCode cc,
-                     CodegenState& state) {
-  vixl::MacroAssembler as { cb };
-
-  if (state.addresses[target]) {
-    not_implemented();
-  }
-
-  // The block hasn't been emitted yet. Record the location in CodegenState.
-  // CodegenState holds a map from Block* to the head of a linked list, where
-  // the jump instructions themselves are the list nodes.
-  auto next = reinterpret_cast<TCA>(state.patches[target]);
-  auto here = cb.frontier();
-
-  // To avoid encoding 0x0 as the jump target. That would conflict with the use
-  // of nullptr as a sentinel return value from jmpTarget() and jccTarget().
-  // Consider switching those to use folly::Optional or something?
-  if (!next) next = kEndOfTargetChain;
-
-  // This will never actually be executed as a jump to "next". It's just a
-  // pointer to the next jump instruction to retarget.
-  mcg->backEnd().emitSmashableJump(cb, next, cc);
-  state.patches[target] = here;
-}
-
-//////////////////////////////////////////////////////////////////////
-
 // copy of ifThen in mc-generator-internal.h
 template <class Then>
 void ifThen(Vout& v, ConditionCode cc, Then thenBlock) {
@@ -1114,11 +1086,8 @@ void CodeGenerator::cgCallHelper(Vout& v,
   auto* taken = m_curInst->taken();
   if (taken && taken->isCatch()) {
     auto& info = m_state.catches[taken];
-    assert(!info.afterCall);
     assert_not_implemented(args.numStackArgs() == 0);
     info.rspOffset = args.numStackArgs();
-    assert(!info.valid);
-    info.valid = true;
     auto next = v.makeBlock();
     v << hcunwind{syncPoint, {next, m_state.labels[taken]}};
     v = next;
@@ -1659,9 +1628,7 @@ void CodeGenerator::cgCall(IRInstruction* inst) {
 
 void CodeGenerator::cgBeginCatch(IRInstruction* inst) {
   UNUSED auto const& info = m_state.catches[inst->block()];
-  assert(info.valid);
   assert(info.rspOffset == 0); // stack args not supported yet
-  assert(info.savedRegs.empty());
 }
 
 static void unwindResumeHelper() {
@@ -1903,7 +1870,6 @@ void CodeGenerator::cgCountCollection(IRInstruction* inst) {
 
 void CodeGenerator::cgInst(IRInstruction* inst) {
   assert(!m_curInst && m_slocs.empty() && m_dlocs.empty());
-  assert(!inst->is(Shuffle));
   m_curInst = inst;
   SCOPE_EXIT {
     m_curInst = nullptr;
diff --git a/hphp/runtime/vm/jit/code-gen-arm.h b/hphp/runtime/vm/jit/code-gen-arm.h
index cfc6b2454a..c02b1ca802 100644
--- a/hphp/runtime/vm/jit/code-gen-arm.h
+++ b/hphp/runtime/vm/jit/code-gen-arm.h
@@ -111,9 +111,6 @@ struct CodeGenerator : public jit::CodeGenerator {
   jit::vector<Vloc>     m_slocs, m_dlocs;
 };
 
-void emitJumpToBlock(CodeBlock& cb, Block* target, ConditionCode cc,
-                     CodegenState& state);
-
 }}}
 
 #endif
diff --git a/hphp/runtime/vm/jit/code-gen-x64.cpp b/hphp/runtime/vm/jit/code-gen-x64.cpp
index ba2d712269..b394a7aa7d 100644
--- a/hphp/runtime/vm/jit/code-gen-x64.cpp
+++ b/hphp/runtime/vm/jit/code-gen-x64.cpp
@@ -259,7 +259,6 @@ ArgGroup CodeGenerator::argGroup() const {
 
 void CodeGenerator::cgInst(IRInstruction* inst) {
   assert(!m_curInst && m_slocs.empty() && m_dlocs.empty());
-  assert(!inst->is(Shuffle));
   m_curInst = inst;
   SCOPE_EXIT {
     m_curInst = nullptr;
@@ -314,7 +313,6 @@ NOOP_OPCODE(ExceptionBarrier)
 NOOP_OPCODE(TakeStack)
 NOOP_OPCODE(TakeRef)
 NOOP_OPCODE(EndGuards)
-NOOP_OPCODE(Shuffle)
 
 CALL_OPCODE(AddElemStrKey)
 CALL_OPCODE(AddElemIntKey)
@@ -570,7 +568,6 @@ void CodeGenerator::cgLdUnwinderValue(IRInstruction* inst) {
 
 void CodeGenerator::cgBeginCatch(IRInstruction* inst) {
   auto const& info = m_state.catches[inst->block()];
-  assert(info.valid);
   auto& v = vmain();
   v << incstat{Stats::TC_CatchTrace, 1, false};
 
@@ -580,7 +577,7 @@ void CodeGenerator::cgBeginCatch(IRInstruction* inst) {
   if (info.rspOffset) {
     v << addqi{info.rspOffset, rsp, rsp};
   }
-  PhysRegSaverParity::emitPops(v, info.savedRegs);
+  PhysRegSaverParity::emitPops(v, RegSet());
 }
 
 static void unwindResumeHelper(_Unwind_Exception* data) {
@@ -1084,10 +1081,7 @@ CodeGenerator::cgCallHelper(Vout& v, CppCall call, const CallDest& dstInfo,
     );
 
     auto& info = m_state.catches[taken];
-    info.savedRegs = RegSet();
     info.rspOffset = regSaver.rspAdjustment();
-    assert(!info.valid);
-    info.valid = true;
     auto next = v.makeBlock();
     v << unwind{{next, m_state.labels[taken]}};
     v = next;
diff --git a/hphp/runtime/vm/jit/code-gen.cpp b/hphp/runtime/vm/jit/code-gen.cpp
index 4e05c8d130..9c501dcb4d 100644
--- a/hphp/runtime/vm/jit/code-gen.cpp
+++ b/hphp/runtime/vm/jit/code-gen.cpp
@@ -34,33 +34,6 @@ TRACE_SET_MOD(hhir);
 
 //////////////////////////////////////////////////////////////////////
 
-/*
- * Compute and save registers that are live *across* each inst, not including
- * registers whose lifetimes end at inst, nor registers defined by inst.
- */
-LiveRegs computeLiveRegs(const IRUnit& unit, const RegAllocInfo& regs) {
-  StateVector<Block, RegSet> live_in(unit, RegSet());
-  LiveRegs live_regs(unit, RegSet());
-  for (bool changed = true; changed;) {
-    changed = false;
-    postorderWalk(unit,
-      [&](Block* block) {
-        RegSet live;
-        if (Block* taken = block->taken()) live = live_in[taken];
-        if (Block* next = block->next()) live |= live_in[next];
-        for (auto it = block->end(); it != block->begin(); ) {
-          IRInstruction& inst = *--it;
-          live -= regs.dstRegs(inst);
-          live_regs[inst] = live;
-          live |= regs.srcRegs(inst);
-        }
-        changed |= (live != live_in[block]);
-        live_in[block] = live;
-      });
-  }
-  return live_regs;
-}
-
 void genCode(IRUnit& unit) {
   if (dumpIREnabled()) {
     AsmInfo ai(unit);
diff --git a/hphp/runtime/vm/jit/code-gen.h b/hphp/runtime/vm/jit/code-gen.h
index 97d217f409..c055d4f36d 100644
--- a/hphp/runtime/vm/jit/code-gen.h
+++ b/hphp/runtime/vm/jit/code-gen.h
@@ -38,58 +38,26 @@ enum class SyncOptions {
 typedef StateVector<IRInstruction, RegSet> LiveRegs;
 
 struct CatchInfo {
-  bool valid;
-  /* afterCall is the address after the call instruction that this catch trace
-   * belongs to. It's the key used to look up catch traces by the
-   * unwinder, since it's the value of %rip during unwinding. */
-  TCA afterCall;
-
-  /* savedRegs contains the caller-saved registers that were pushed onto the
-   * C++ stack at the time of the call. The catch trace will pop these
-   * registers (in the same order as PhysRegSaver's destructor) before doing
-   * any real work to restore the register state from before the call. */
-  RegSet savedRegs;
-
-  /* rspOffset is the number of bytes pushed on the C++ stack after the
-   * registers in savedRegs were saved, typically from function calls with >6
-   * arguments. The catch trace will adjust rsp by this amount before popping
-   * anything in savedRegs. */
+  /* rspOffset is the number of bytes pushed on the C++ stack for the call,
+   * for functions with stack arguments. The catch trace will adjust rsp
+   * by this amount before executing the catch block */
   Offset rspOffset;
 };
 
 // Stuff we need to preserve between blocks while generating code,
 // and address information produced during codegen.
 struct CodegenState {
-  CodegenState(const IRUnit& unit, const RegAllocInfo& regs,
-               const LiveRegs& liveRegs, AsmInfo* asmInfo)
-    : patches(unit, nullptr)
-    , addresses(unit, nullptr)
-    , regs(regs)
-    , liveRegs(liveRegs)
-    , asmInfo(asmInfo)
+  CodegenState(const IRUnit& unit, AsmInfo* asmInfo)
+    : asmInfo(asmInfo)
     , catches(unit, CatchInfo())
-    , pastGuards(false)
     , labels(unit, Vlabel())
     , locs(unit, Vloc{})
   {}
 
-  // Each block has a list of addresses to patch, and an address if
-  // it's already been emitted.
-  StateVector<Block,void*> patches;
-  StateVector<Block,TCA> addresses;
-
   // True if this block's terminal Jmp has a desination equal to the
   // next block in the same assmbler.
   bool noTerminalJmp;
 
-  // output from register allocator
-  const RegAllocInfo& regs;
-
-  // for each instruction, holds the RegSet of registers that must be
-  // preserved across that instruction.  This is for push/pop of caller-saved
-  // registers.
-  const LiveRegs& liveRegs;
-
   // Output: start/end ranges of machine code addresses of each instruction.
   AsmInfo* asmInfo;
 
@@ -100,18 +68,18 @@ struct CodegenState {
   // Have we progressed past the guards? Used to suppress TransBCMappings until
   // we're translating code that can properly be attributed to specific
   // bytecode.
-  bool pastGuards;
+  bool pastGuards{false};
 
   // Postponed code "points" can obtain code addresses after Vasm::finish().
   Vmeta meta;
 
   // vasm block labels, one for each hhir block
   StateVector<Block,Vlabel> labels;
+
+  // vlocs for each SSATmp used or defined in reachable blocks
   StateVector<SSATmp,Vloc> locs;
 };
 
-LiveRegs computeLiveRegs(const IRUnit& unit, const RegAllocInfo& regs);
-
 // Allocate registers and generate machine code. Mutates the global
 // singleton MCGenerator (adds code, allocates data, adds fixups).
 void genCode(IRUnit&);
diff --git a/hphp/runtime/vm/jit/extra-data.h b/hphp/runtime/vm/jit/extra-data.h
index 294d410249..623be416ae 100644
--- a/hphp/runtime/vm/jit/extra-data.h
+++ b/hphp/runtime/vm/jit/extra-data.h
@@ -725,26 +725,6 @@ struct RBTraceData : IRExtraData {
   const StringData* msg;
 };
 
-/*
- * ShuffleData holds an array of destination locations for a Shuffle,
- * one per source, as well as a capacity field so we can track the
- * available space to add more srcs and dsts without reallocating.
- */
-struct ShuffleData : IRExtraData {
-  ShuffleData(PhysLoc* dests, uint32_t size, uint32_t cap)
-    : dests(dests), size(size), cap(cap)
-  {}
-
-  std::string show() const;
-
-  PhysLoc* begin() const { return dests; }
-  PhysLoc* end()   const { return dests + size; }
-
-  PhysLoc* dests; // array of up to [cap] PhysLocs
-  uint32_t size; // number of valid dests
-  uint32_t cap; // available slots for more dests & srcs
-};
-
 struct ClassKindData : IRExtraData {
   explicit ClassKindData(ClassKind kind): kind(uint32_t(kind)) {}
 
@@ -932,7 +912,6 @@ X(InterpOneCF,                  InterpOneData);
 X(StClosureFunc,                FuncData);
 X(StClosureArg,                 PropByteOffset);
 X(RBTrace,                      RBTraceData);
-X(Shuffle,                      ShuffleData);
 X(OODeclExists,                 ClassKindData);
 X(NewStructArray,               NewStructData);
 X(LdRaw,                        RawMemData);
diff --git a/hphp/runtime/vm/jit/ir-instruction.cpp b/hphp/runtime/vm/jit/ir-instruction.cpp
index a22ce04622..26e2cef204 100644
--- a/hphp/runtime/vm/jit/ir-instruction.cpp
+++ b/hphp/runtime/vm/jit/ir-instruction.cpp
@@ -340,29 +340,6 @@ void IRInstruction::setOpcode(Opcode newOpc) {
   m_op = newOpc;
 }
 
-void IRInstruction::addCopy(IRUnit& unit, SSATmp* src, const PhysLoc& dest) {
-  assert(op() == Shuffle);
-  auto data = extra<Shuffle>();
-  auto n = numSrcs();
-  assert(n == data->size && n <= data->cap);
-  if (n == data->cap) {
-    auto cap = data->cap * 2;
-    auto srcs = new (unit.arena()) SSATmp*[cap];
-    auto dests = new (unit.arena()) PhysLoc[cap];
-    for (unsigned i = 0; i < n; i++) {
-      srcs[i] = m_srcs[i];
-      dests[i] = data->dests[i];
-    }
-    m_srcs = srcs;
-    data->dests = dests;
-    data->cap = cap;
-  }
-  m_numSrcs = n + 1;
-  m_srcs[n] = src;
-  data->size = n + 1;
-  data->dests[n] = dest;
-}
-
 SSATmp* IRInstruction::src(uint32_t i) const {
   always_assert(i < numSrcs());
   return m_srcs[i];
diff --git a/hphp/runtime/vm/jit/ir-instruction.h b/hphp/runtime/vm/jit/ir-instruction.h
index 2067d96f67..8428637968 100644
--- a/hphp/runtime/vm/jit/ir-instruction.h
+++ b/hphp/runtime/vm/jit/ir-instruction.h
@@ -178,11 +178,6 @@ struct IRInstruction {
    */
   void become(IRUnit&, IRInstruction* other);
 
-  /*
-   * Add an additional src SSATmp and dst Operand to this Shuffle.
-   */
-  void addCopy(IRUnit&, SSATmp* src, const PhysLoc& dest);
-
   bool       is() const { return false; }
   template<typename... Args>
   bool       is(Opcode op, Args&&... args) const {
diff --git a/hphp/runtime/vm/jit/ir.h b/hphp/runtime/vm/jit/ir.h
index 9be6ee9928..1732299e26 100644
--- a/hphp/runtime/vm/jit/ir.h
+++ b/hphp/runtime/vm/jit/ir.h
@@ -562,7 +562,6 @@ O(InterpOne,                 D(StkPtr), S(StkPtr) S(FramePtr),                \
                                                                       E|N|Er) \
 O(InterpOneCF,               D(StkPtr), S(StkPtr) S(FramePtr),                \
                                                                     T|E|N|Er) \
-O(Shuffle,                          ND, SVar(Top),                        NF) \
 O(CreateCont,                   D(Obj), S(FramePtr) C(Int)                    \
                                           S(TCA,Nullptr) C(Int),   E|NNT|PRc) \
 O(ContEnter,                 D(StkPtr), S(StkPtr)                             \
diff --git a/hphp/runtime/vm/jit/print.cpp b/hphp/runtime/vm/jit/print.cpp
index 344523f47b..1d1a467332 100644
--- a/hphp/runtime/vm/jit/print.cpp
+++ b/hphp/runtime/vm/jit/print.cpp
@@ -222,17 +222,6 @@ void printPhysLoc(std::ostream& os, const PhysLoc& loc) {
   }
 }
 
-std::string ShuffleData::show() const {
-  std::ostringstream os;
-  auto delim = "";
-  for (unsigned i = 0; i < size; ++i) {
-    os << delim;
-    printPhysLoc(os, dests[i]);
-    delim = ",";
-  }
-  return os.str();
-}
-
 void print(std::ostream& os, const SSATmp* tmp, const PhysLoc* loc) {
   if (tmp->inst()->is(DefConst)) {
     os << constToString(tmp->type());
diff --git a/hphp/runtime/vm/jit/reg-alloc-arm.h b/hphp/runtime/vm/jit/reg-alloc-arm.h
index ed7e66edfc..8b02b2bffd 100644
--- a/hphp/runtime/vm/jit/reg-alloc-arm.h
+++ b/hphp/runtime/vm/jit/reg-alloc-arm.h
@@ -22,68 +22,8 @@
 
 namespace HPHP { namespace jit {
 
-using NativeCalls::CallMap;
-
 namespace arm {
 
-// Return true if the CodeGenerator method for this instruction can
-// handle an immediate for the ith source operand, usually by selecting
-// a special form of the necessary instruction.  The value of the immediate
-// can affect this decision; we look at the value here, and trust it
-// blindly in CodeGenerator.
-bool mayUseConst(const IRInstruction& inst, unsigned i) {
-  assert(inst.src(i)->isConst());
-  union {
-    int64_t cint;
-    double cdouble;
-  };
-  auto type = inst.src(i)->type();
-  cint = type.rawVal();
-  // (almost?) any instruction that accepts a GPR, can accept XZR in
-  // place of an immediate zero. TODO #3827905
-  switch (inst.op()) {
-  case GuardRefs:
-  case CheckRefs:
-    if (i == 1) return inst.src(2)->intVal() == 0; // nParams
-    if (i == 3) { // mask64
-      return vixl::Assembler::IsImmLogical(cint, vixl::kXRegSize);
-    }
-    if (i == 4) { // vals64
-      return vixl::Assembler::IsImmArithmetic(cint);
-    }
-    break;
-
-  //TODO: t3944093 add constraints for existing arm codegen
-  default:
-    break;
-  }
-  if (CallMap::hasInfo(inst.op())) {
-    // shuffleArgs() knows what to do with immediates.
-    // TODO: #3634984 ... but it needs a scratch register
-    return true;
-  }
-  return false;
-}
-
-Constraint srcConstraint(const IRInstruction& inst, unsigned i) {
-  Constraint c { Constraint::GP };
-  if (inst.src(i)->isConst() && mayUseConst(inst, i)) {
-    c |= Constraint::IMM;
-  }
-  if (inst.src(i)->type() <= Type::Dbl) {
-    c |= Constraint::SIMD;
-  }
-  return c;
-}
-
-Constraint dstConstraint(const IRInstruction& inst, unsigned i) {
-  Constraint c { Constraint::GP };
-  if (inst.dst(i)->type() <= Type::Dbl) {
-    c |= Constraint::SIMD;
-  }
-  return c;
-}
-
 }}}
 
 #endif
diff --git a/hphp/runtime/vm/jit/reg-alloc-x64.h b/hphp/runtime/vm/jit/reg-alloc-x64.h
index b836b2ad4f..ff44d614d8 100644
--- a/hphp/runtime/vm/jit/reg-alloc-x64.h
+++ b/hphp/runtime/vm/jit/reg-alloc-x64.h
@@ -30,193 +30,6 @@ using NativeCalls::CallMap;
 
 namespace x64 {
 
-// okStore is true if cgStore can take c as an immediate without
-// using any scratch registers.
-bool okStore(int64_t c) { return true; }
-
-// return true if cgCallHelper and ArgGroup accept c as immediate.
-bool okArg(int64_t c) { return true/*isI32(c)*/; }
-
-// return true if CodeGenerator supports this operand as an
-// immediate value.
-// pre: the src must actually be a const
-bool mayUseConst(const IRInstruction& inst, unsigned i) {
-  assert(inst.src(i)->isConst());
-  union {
-    int64_t cint;
-    double cdouble;
-  };
-  auto type = inst.src(i)->type();
-  cint = type.rawVal();
-  switch (inst.op()) {
-  case GuardRefs:
-  case CheckRefs:
-    if (i == 1) return inst.src(2)->intVal() == 0; // nParams
-    if (i == 3) return isU32(cint); // mask64
-    if (i == 4) return isU32(cint); // vals64
-    break;
-  case LdPackedArrayElem:
-  case CheckPackedArrayElemNull:
-    if (i == 1) return true; // idx; can use reg+imm addressing mode
-    break;
-  case SpillStack:
-    if (i >= 2) return okStore(cint);
-    break;
-  case SpillFrame:
-    if (i == 1) return true; // func
-    if (i == 2 && type <= Type::Cls) return true;     // objOrCls is Cls
-    if (i == 2 && type <= Type::Nullptr) return true; // objOrCls is null
-    break;
-  case StRetVal:
-    if (i == 1) return okStore(cint); // value->cgStore
-    break;
-  case StaticLocInitCached:
-    if (i == 1) return okStore(cint); // value->cgStore
-    break;
-  case StContArRaw:
-    if (i == 2) return okStore(cint); // value->x64-store-imm
-    break;
-  case StContArValue:
-    if (i == 1) return okStore(cint); // value->cgStore
-    break;
-  case LdGblAddr:
-    if (i == 0) return okArg(cint); // name passed to ArgGroup.ssa
-    break;
-  case StElem:
-    if (i == 1) return isI32(cint); // idx used as d32 imm offset
-    break;
-  case LdElem:
-    if (i == 1) return isI32(cint); // byte offset used in MemoryRef
-    break;
-  case StRef:
-    if (i == 1) return okStore(cint);
-    break;
-  case CallBuiltin:
-    return true;
-  case StLoc:
-  case StLocNT:
-    if (i == 1) return okStore(cint); // value
-    break;
-  case StProp:
-  case StMem:
-    if (i == 2) return okStore(cint); // value
-    break;
-  case StRaw:
-    if (i == 2) return okStore(cint); // value
-    break;
-  case Jmp:
-  case Shuffle:
-    // doRegMoves handles immediates.
-    // TODO: #3634984 ... but it needs a scratch register
-    return true;
-  case LdClsPropAddrOrNull:
-    if (i == 0) return okArg(cint); // cls -> ArgGroup.ssa().
-    if (i == 1) return okArg(cint); // prop -> ArgGroup.ssa().
-    break;
-  case LdClsPropAddrOrRaise:
-    if (i == 0) return okArg(cint); // cls -> ArgGroup.ssa().
-    if (i == 1) return okArg(cint); // prop -> ArgGroup.ssa().
-    break;
-  case Same: case NSame:
-  case Eq:   case EqX:
-  case Neq:  case NeqX:
-  case Lt:   case LtX:
-  case Gt:   case GtX:
-  case Lte:  case LteX:
-  case Gte:  case GteX:
-    if (i == 1) {
-      // cases in cgCmpHelper()
-      auto type0 = inst.src(0)->type();
-      if (type0 <= Type::Str && type <= Type::Str) return true; // call
-      if (type0 <= Type::Bool && type <= Type::Bool) return true;
-      if (type0 <= Type::Obj && type <= Type::Int) return true;
-      if (type0 <= Type::Arr && type <= Type::Arr) return true;
-    }
-    break;
-  case JmpEq:  case SideExitJmpEq:  case ReqBindJmpEq:
-  case JmpNeq: case SideExitJmpNeq: case ReqBindJmpNeq:
-  case JmpGt:  case SideExitJmpGt:  case ReqBindJmpGt:
-  case JmpGte: case SideExitJmpGte: case ReqBindJmpGte:
-  case JmpLt:  case SideExitJmpLt:  case ReqBindJmpLt:
-  case JmpLte: case SideExitJmpLte: case ReqBindJmpLte:
-    if (i == 1) {
-      // cases in emitCompare()
-      auto type0 = inst.src(0)->type();
-      if (type0 <= Type::Bool && type <= Type::Bool) return true;
-      if (type0 <= Type::Cls && type <= Type::Cls) return isI32(cint);
-    }
-    break;
-  case EqInt:
-  case NeqInt:
-  case LtInt:
-  case GtInt:
-  case LteInt:
-  case GteInt:
-  case JmpEqInt:  case SideExitJmpEqInt:  case ReqBindJmpEqInt:
-  case JmpNeqInt: case SideExitJmpNeqInt: case ReqBindJmpNeqInt:
-  case JmpGtInt:  case SideExitJmpGtInt:  case ReqBindJmpGtInt:
-  case JmpGteInt: case SideExitJmpGteInt: case ReqBindJmpGteInt:
-  case JmpLtInt:  case SideExitJmpLtInt:  case ReqBindJmpLtInt:
-  case JmpLteInt: case SideExitJmpLteInt: case ReqBindJmpLteInt:
-    // cases in emitCompareInt()
-    if (i == 1) return isI32(cint);
-    break;
-  case AddInt:
-  case AndInt:
-  case OrInt:
-  case XorInt:
-    if (i == 1) return !inst.src(0)->isConst() && isI32(cint); // X op C
-    break;
-  case SubInt:
-    if (i == 0) return cint == 0 && !inst.src(1)->isConst(); // 0-X
-    if (i == 1) return !inst.src(0)->isConst() && isI32(cint); // X-C
-    break;
-  case Shl: case Shr:
-    if (i == 1) return true; // shift amount
-    break;
-  case XorBool:
-    if (i == 1) return isI32(cint);
-    break;
-  case Mov:
-    return true; // x64 can mov a 64-bit imm into a register.
-  case StringIsset:
-    if (i == 1) return isI32(cint);
-    break;
-  case CheckPackedArrayBounds:
-    if (i == 1) return isI32(cint); // idx
-    break;
-  case AKExists:
-    // both args are passed to cgCallHelper
-    if (i == 0) return okArg(cint);
-    if (i == 1) return okArg(cint);
-    break;
-  case CheckBounds:
-    if (i == 0) { // idx
-      return !inst.src(1)->isConst() && isI32(cint) && cint >= 0;
-    }
-    if (i == 1) { // size
-      return !inst.src(0)->isConst() && isI32(cint) && cint >= 0;
-    }
-    break;
-  case VerifyParamCls:
-  case VerifyRetCls:
-    if (i == 1) return isI32(cint); // constraint class ptr
-    break;
-  case FunctionReturnHook:
-    if (i == 1) return okStore(cint); // return value
-    break;
-  default:
-    break;
-  }
-  if (CallMap::hasInfo(inst.op())) {
-    // shuffleArgs() knows what to do with immediates.
-    // TODO: #3634984 ... but it needs a scratch register for
-    // big constants, so handle big immediates here.
-    return true;
-  }
-  return false;
-}
-
 /*
  * Return true if this instruction can load a TypedValue using a 16-byte
  * load into a SIMD register.  Note that this function returns
@@ -289,74 +102,6 @@ bool storesCell(const IRInstruction& inst, uint32_t srcIdx) {
   }
 }
 
-Constraint srcConstraint(const IRInstruction& inst, unsigned i) {
-  Constraint c { Constraint::GP };
-  auto src = inst.src(i);
-  if (src->isConst() && mayUseConst(inst, i)) {
-    c |= Constraint::IMM;
-  }
-  if (src->type() <= Type::Dbl) {
-    c |= Constraint::SIMD;
-  } else if (!packed_tv && storesCell(inst, i) && src->numWords() == 2) {
-    // don't do this for packed_tv because the type byte is hard to access
-    // don't do it for control-flow instructions because we assume the
-    // instruction is looking at the type-byte.
-    c |= Constraint::SIMD;
-  }
-  return c;
-}
-
-// Return true by default to indicate a result register is required even
-// if the instruction's dst is unused.  It's only useful to return false
-// for instructions that have a side effect, *and* have the CodeGenerator
-// logic to detect no result register and emit better code.
-bool needsUnusedReg(const IRInstruction& inst, unsigned dst) {
-  // helpers that check for InvalidReg dest:
-  // cgCallHelper
-  // cgLoad
-  // cgLoadTypedValue
-  switch (inst.op()) {
-  default: return true;
-
-  // These have an explicit check for InvalidReg dst
-  case CheckNonNull:
-
-  // These use cgCallHelper, which has an explicit check
-  case CallBuiltin:
-
-  // these use cgLdFuncCachedCommon, which checks for no dest
-  case LdFuncCached:
-  case LdFuncCachedU:
-  case LdFuncCachedSafe:
-
-  // These are optional branches, so DCE may not remove them, and use
-  // cgLoad, which checks for InvalidReg
-  case LdRef:
-  case LdMem:
-     break;
-  }
-  return false;
-}
-
-Constraint dstConstraint(const IRInstruction& inst, unsigned i) {
-  Constraint c { Constraint::GP };
-  auto dst = inst.dst(i);
-  if (dst->type() <= Type::Dbl) {
-    c |= Constraint::SIMD;
-  } else if (!packed_tv && loadsCell(inst.op()) && !inst.isControlFlow() &&
-             dst->numWords() == 2) {
-    // we don't do this for packed_tv because the type byte is at offset 1
-    // we don't do this for isControlFlow() under the assumption the instruction
-    // is some kind of type-check, no such instruction would be peeking into
-    // the XMM to examine the type-byte.
-    c |= Constraint::SIMD;
-  }
-  if (!needsUnusedReg(inst, i)) {
-    c |= Constraint::VOID;
-  }
-  return c;
-}
-
 }}}
 
 #endif
diff --git a/hphp/runtime/vm/jit/reg-alloc.cpp b/hphp/runtime/vm/jit/reg-alloc.cpp
index 79ed4b6a45..64b342cc00 100644
--- a/hphp/runtime/vm/jit/reg-alloc.cpp
+++ b/hphp/runtime/vm/jit/reg-alloc.cpp
@@ -135,69 +135,4 @@ void assignRegs(IRUnit& unit, Vunit& vunit, CodegenState& state,
   }
 }
 
-namespace {
-// This implements an array of arrays of bools, one for each declared
-// source operand of each instruction.  True means the operand must
-// be a const; i.e. it was declared with C(T) instead of S(T).
-struct ConstSrcTable {
-  auto static constexpr MaxSrc = 8;
-  bool table[kNumOpcodes][MaxSrc];
-  ConstSrcTable() {
-    int op = 0;
-    int i;
-
-#define NA
-#define S(...)       i++;
-#define AK(kind)     i++;
-#define C(type)      table[op][i++] = true;
-#define CStr         table[op][i++] = true;
-#define SNumInt      i++;
-#define SNum         i++;
-#define SVar(...)
-#define O(opcode, dstinfo, srcinfo, flags) \
-    i = 0; \
-    srcinfo \
-    op++;
-
-    IR_OPCODES
-
-#undef O
-#undef NA
-#undef SAny
-#undef S
-#undef AK
-#undef C
-#undef CStr
-#undef SNum
-#undef SVar
-
-  }
-  bool mustBeConst(int op, int i) const {
-    return i < MaxSrc ? table[op][i] : false;
-  }
-};
-const ConstSrcTable g_const_table;
-
-// Return true if the ith source operand must be a constant.  This
-// information comes from the table above.
-bool mustUseConst(const IRInstruction& inst, int i) {
-  bool b = g_const_table.mustBeConst(static_cast<int>(inst.op()), i);
-  assert(!b || inst.src(i)->isConst());
-  return b;
-}
-}
-
-Constraint srcConstraint(const IRInstruction& inst, unsigned i) {
-  auto r = forceAlloc(*inst.src(i));
-  if (r != InvalidReg) return r;
-  if (mustUseConst(inst, i)) return Constraint::IMM;
-  return mcg->backEnd().srcConstraint(inst, i);
-}
-
-Constraint dstConstraint(const IRInstruction& inst, unsigned i) {
-  auto r = forceAlloc(*inst.dst(i));
-  if (r != InvalidReg) return r;
-  return mcg->backEnd().dstConstraint(inst, i);
-}
-
 }}
diff --git a/hphp/runtime/vm/jit/reg-alloc.h b/hphp/runtime/vm/jit/reg-alloc.h
index 134dcd4422..2f21ae3945 100644
--- a/hphp/runtime/vm/jit/reg-alloc.h
+++ b/hphp/runtime/vm/jit/reg-alloc.h
@@ -105,15 +105,9 @@ struct RegAllocInfo {
 
   RegSet dstRegs(const IRInstruction& inst) const {
     auto regs = RegSet();
-    if (inst.is(Shuffle)) {
-      for (auto const& dest : *inst.extra<Shuffle>()) {
-        regs |= dest.regs();
-      }
-    } else {
-      auto& map = m_regs[inst];
-      for (unsigned i = 0, n = inst.numDsts(); i < n; ++i) {
-        regs |= map.dst(i).regs();
-      }
+    auto& map = m_regs[inst];
+    for (unsigned i = 0, n = inst.numDsts(); i < n; ++i) {
+      regs |= map.dst(i).regs();
     }
     return regs;
   }
@@ -122,88 +116,6 @@ private:
   StateVector<IRInstruction,RegMap> m_regs;
 };
 
-/*
- * New register allocator doing extended linear scan
- */
-RegAllocInfo allocateRegs(IRUnit&);
-
-/*
- * A Constraint represents a set of locations an operand may
- * be assigned to by the register allocator.  GP and SIMD are
- * self explanitory.  VOID means no-location, i.e. InvalidReg.
- * Only some instructions allow a VOID destination, so VOID
- * is explicit.
- */
-struct Constraint {
-  enum Mask: uint8_t {
-    GP = 1,
-    SIMD = 2,
-    VOID = 4,   // used for unused dests that can be InvalidReg
-    IMM = 8
-  };
-
-  /* implicit */ Constraint(Mask m)
-    : m_mask(m)
-    , m_reg(InvalidReg)
-  {}
-  /* implicit */ Constraint(PhysReg r)
-    : m_mask(maskFromReg(r))
-    , m_reg(r)
-  {}
-
-  Constraint& operator=(Constraint c2) {
-    m_mask = c2.m_mask;
-    m_reg = c2.m_reg;
-    return *this;
-  }
-
-  bool operator==(Constraint c2) const {
-    return m_mask == c2.m_mask && m_reg == c2.m_reg;
-  }
-
-  bool operator!=(Constraint c2) const {
-    return !(*this == c2);
-  }
-
-  PhysReg reg() const { return m_reg; }
-
-  Constraint operator|(Constraint c2) const {
-    return (*this == c2) ? *this :
-           Constraint(Mask(m_mask | c2.m_mask));
-  }
-
-  Constraint operator&(Constraint c2) const {
-    return (*this == c2) ? *this :
-           Constraint(Mask(m_mask & c2.m_mask));
-  }
-
-  Constraint operator-(Constraint c2) const {
-    assert(m_reg == InvalidReg && c2.m_reg == InvalidReg);
-    return Mask(m_mask & ~c2.m_mask);
-  }
-
-  Constraint& operator|=(Constraint c2) { return *this = *this | c2; }
-  Constraint& operator&=(Constraint c2) { return *this = *this & c2; }
-  Constraint& operator-=(Constraint c2) { return *this = *this - c2; }
-
-  explicit operator bool() const { return m_mask != 0; }
-
-private:
-  static Mask maskFromReg(PhysReg r) {
-    return r.isGP() ? GP : r.isSIMD() ? SIMD : VOID;
-  }
-
-private:
-  Mask m_mask;
-  PhysReg m_reg; // if valid, force this register
-};
-
-// return a constraint for the given src
-Constraint srcConstraint(const IRInstruction& inst, unsigned src);
-
-// Return a constraint for the given destination.
-Constraint dstConstraint(const IRInstruction& inst, unsigned dst);
-
 // Return InvalidReg, or a specific register to force tmp to use
 PhysReg forceAlloc(const SSATmp& tmp);
 
diff --git a/hphp/runtime/vm/jit/xls.cpp b/hphp/runtime/vm/jit/xls.cpp
deleted file mode 100644
index 6bd22796ae..0000000000
--- a/hphp/runtime/vm/jit/xls.cpp
+++ /dev/null
@@ -1,1563 +0,0 @@
-/*
-   +----------------------------------------------------------------------+
-   | HipHop for PHP                                                       |
-   +----------------------------------------------------------------------+
-   | Copyright (c) 2010-2014 Facebook, Inc. (http://www.facebook.com)     |
-   +----------------------------------------------------------------------+
-   | This source file is subject to version 3.01 of the PHP license,      |
-   | that is bundled with this package in the file LICENSE, and is        |
-   | available through the world-wide-web at the following url:           |
-   | http://www.php.net/license/3_01.txt                                  |
-   | If you did not receive a copy of the PHP license and are unable to   |
-   | obtain it through the world-wide-web, please send a note to          |
-   | license@php.net so we can mail you a copy immediately.               |
-   +----------------------------------------------------------------------+
-*/
-
-#include "hphp/runtime/vm/jit/state-vector.h"
-#include "hphp/runtime/vm/jit/id-set.h"
-#include "hphp/runtime/vm/jit/block.h"
-#include "hphp/runtime/vm/jit/cfg.h"
-#include "hphp/runtime/vm/jit/print.h"
-#include "hphp/runtime/vm/jit/punt.h"
-#include "hphp/runtime/vm/jit/check.h"
-#include "hphp/runtime/vm/jit/timer.h"
-#include "hphp/runtime/vm/jit/reg-alloc.h"
-#include "hphp/runtime/vm/jit/mc-generator.h"
-
-#include <unordered_set>
-#include <algorithm>
-#include <utility>
-
-#ifdef VOID
-#undef VOID
-#endif
-
-// TODO
-//  - #3098109 dests of branch instructions start in next block
-//  - #3098509 streamline code, vectors vs linked lists, etc
-//  - #3409409 Enable use of SIMD at least for doubles, for packed_tv
-//  - #3098685 Optimize lifetime splitting
-//  - #3098712 reuse spill slots
-//  - #3098739 new features now possible with XLS
-//  - #3099647 support loops
-
-namespace HPHP { namespace jit {
-TRACE_SET_MOD(xls);
-namespace {
-using namespace reg;
-struct Interval;
-struct RegPositions;
-
-typedef StateVector<SSATmp, Interval*> Intervals;
-typedef IdSet<SSATmp> LiveSet;
-
-// A Use refers to the position where an interval is read or written.
-// The hint is used by firstHint() to try picking a good register.
-struct Use {
-  enum Kind {
-    kNone,   // ordinary use or def, but no hints
-    kReg,    // precoloring hint in regHint
-    kCopy,   // this use is a copy dest; srcId is copy src
-    kPhiSrc, // this use is a Jmp src; phiIndex is which src
-    kPhiDst  // this use is a DefLabel dst; phiIndex is which dest
-  };
-  Use(){}
-  explicit Use(unsigned pos) : pos(pos), kind(kNone) {}
-  Use(unsigned pos, RegPair regs)
-    : pos(pos)
-    , kind(regs.first != InvalidReg ? kReg : kNone)
-    , regHint(regs)
-  {}
-  Use(unsigned pos, SSATmp* s)
-    : pos(pos)
-    , kind(kCopy)
-    , srcId(s->id())
-  {}
-  Use(unsigned pos, Kind k, unsigned i)
-    : pos(pos)
-    , kind(k)
-    , phiIndex(i)
-  {}
-  unsigned pos;
-  Kind kind;
-  union {
-    RegPair regHint;   // precoloring hint
-    uint32_t srcId;    // ssatmp id of related copy
-    unsigned phiIndex; // which jmp src or deflabel dest
-  };
-};
-
-// A LiveRange is an open-ended range of positions where an interval is live.
-struct LiveRange {
-  LiveRange(unsigned s, unsigned e) : start(s), end(e) { assert(s <= e); }
-  bool contains(unsigned pos) const { return pos >= start && pos < end; }
-  bool intersects(LiveRange r) const { return r.start < end && start < r.end; }
-  bool contains(LiveRange r) const;
-public:
-  unsigned start, end;
-};
-
-// An Interval stores the lifetime of an SSATmp as a sorted list of disjoint
-// ranges, and a sorted list of use positions.  If this interval was split,
-// then the first interval is deemed "parent" and the rest are "children",
-// and they're all connected as a singly linked list sorted by start.
-//
-// Every use position must be inside one of the ranges, or exactly at the
-// end of the last range.  Allowing a use exactly at the end facilitates
-// lifetime splitting when the use is a call argument that clobbers the
-// argument registers; we need to split the lifetime exactly at the call
-// position, which is exactly where the use is.
-struct Interval {
-  Interval() {}
-  explicit Interval(Interval* parent);
-  // accessors
-  bool empty() const { return ranges.empty(); }
-  unsigned start() const { return ranges.front().start; }
-  unsigned end() const { return ranges.back().end; }
-  Interval* leader() { return parent ? parent : this; }
-  const Interval* leader() const { return parent ? parent : this; }
-  bool isChild() const { return parent != nullptr; }
-  // queries
-  bool covers(unsigned pos) const;
-  bool usedAt(unsigned pos) const;
-  Interval* childAt(unsigned pos);
-  unsigned nextIntersect(Interval*) const;
-  unsigned firstUseAfter(unsigned pos) const;
-  unsigned lastUseBefore(unsigned pos) const;
-  unsigned firstUse() const;
-  // mutators
-  void add(LiveRange r);
-  void addUse(Use u) { uses.push_back(u); }
-  Interval* split(unsigned pos, bool keep_uses = false);
-  // register/spill assignment
-  RegPair regs() const;
-  bool handled() const { return loc.hasReg(0) || loc.spilled(); }
-  // debugging
-  std::string toString();
-  bool checkInvariants() const;
-  uint32_t id() const { return tmp->id(); }
-public:
-  bool blocked { false }; // cannot be spilled
-  bool scratch { false }; // used as scratch or arg, cannot be spilled
-  uint8_t need { 0 }; // number of required registers (exactly 1 or 2)
-  RegSet allow;
-  RegSet prefer;
-  SSATmp* tmp { nullptr };
-  Interval* parent { nullptr }; // if this is a split-off child
-  Interval* next { nullptr }; // next split child or nullptr
-  jit::vector<LiveRange> ranges;
-  jit::vector<Use> uses;
-  PhysLoc loc;  // current location assigned to this interval
-  PhysLoc spill; // spill location (parent only)
-};
-
-// Extended Linear Scan. This just encapsulates the intermediate
-// data structures we use during the algorithm so we don't have
-// to pass them around everywhere.
-struct XLS {
-  typedef jit::vector<Interval*> IntervalList;
-  XLS(IRUnit& unit, RegAllocInfo& regs, const Abi&);
-  ~XLS();
-  void allocate();
-  // phases
-  void prepareBlocks();
-  void computePositions();
-  void buildIntervals();
-  void walkIntervals();
-  void assignLocations();
-  void resolveSplits();
-  void resolveEdges();
-  // utilities
-  void enqueue(Interval* interval);
-  void allocOne(Interval* current);
-  void allocBlocked(Interval* current);
-  void spill(Interval*);
-  void spillAfter(Interval* ivl, unsigned pos);
-  void spillOthers(Interval* current, RegPair r);
-  void assignReg(Interval*, RegPair r);
-  void assignSpill(Interval*);
-  void update(unsigned pos);
-  void insertCopy(Block* b, Block::iterator, IRInstruction*& shuffle,
-                  SSATmp* src, const PhysLoc& rs, const PhysLoc& rd);
-  void insertSpill(Interval* ivl);
-  void resolveFlow(Interval* ivl, Block* pred, Block* succ,
-                   unsigned pos1, unsigned pos2);
-  Use coalesceSrc(unsigned pos, const IRInstruction&, unsigned i);
-  Use coalesceDst(unsigned pos, const IRInstruction&, unsigned i);
-  RegPair firstHint(Interval*, const RegPositions&);
-  static void erase(IntervalList& list, IntervalList::iterator it);
-  // debugging
-  void print(const char* caption);
-  void dumpIntervals();
-private:
-  struct Compare { bool operator()(const Interval*, const Interval*); };
-private:
-  Intervals m_intervals; // parent intervals indexed by ssatmp
-  unsigned m_nextSpill { 0 };
-  IRUnit& m_unit;
-  RegAllocInfo& m_regs;
-  const Abi& m_abi;
-  StateVector<IRInstruction, unsigned> m_posns;
-  jit::vector<IRInstruction*> m_insts;
-  BlockList m_blocks;
-  PhysReg::Map<Interval> m_scratch;
-  PhysReg::Map<Interval> m_blocked;
-  StateVector<Block,LiveSet> m_liveIn;
-  jit::priority_queue<Interval*,Compare> m_pending;
-  IntervalList m_active;
-  IntervalList m_inactive;
-  StateVector<Block,std::pair<IRInstruction*,IRInstruction*>> m_edgeCopies;
-  unsigned m_frontier { 0 }; // debug_only to detect backtracking
-  unsigned m_orig { 0 };
-  unsigned m_final { 0 };
-  unsigned m_copies { 0 };
-  unsigned m_spills { 0 };
-  unsigned m_reloads { 0 };
-  unsigned m_ldconst { 0 };
-};
-
-// "infinity" use position
-constexpr uint32_t kMaxPos = std::numeric_limits<uint32_t>::max();
-
-// Keep track of a future use or conflict position for each register.
-// Initially all usable registers have kMaxPos
-struct RegPositions {
-  explicit RegPositions();
-  unsigned find1(RegSet allow, RegPair& regs) const;
-  unsigned find2(RegSet allow, RegPair& regs) const;
-  unsigned find(Interval* ivl, RegSet allow, RegPair& regs) const;
-  unsigned getPos(Interval*, RegPair regs) const;
-  unsigned setPos(Interval*, unsigned pos);
-private:
-  PhysReg::Map<unsigned> posns;
-};
-
-//////////////////////////////////////////////////////////////////////////////
-
-// returns true if this range contains r
-bool LiveRange::contains(LiveRange r) const {
-  return r.start >= start && r.end <= end;
-}
-
-//////////////////////////////////////////////////////////////////////////////
-
-bool isDefConst(const Interval* ivl) {
-  return ivl->tmp->inst()->is(DefConst);
-}
-
-Interval::Interval(Interval* parent)
-  : need(parent->need)
-  , allow(parent->allow)
-  , prefer(parent->prefer)
-  , tmp(parent->tmp)
-  , parent(parent)
-{}
-
-// Add r to this interval, merging r with any existing overlapping ranges
-void Interval::add(LiveRange r) {
-  assert(blocked || scratch || r.start < r.end);
-  while (!ranges.empty() && r.contains(ranges.back())) {
-    ranges.pop_back();
-  }
-  if (ranges.empty()) {
-    return ranges.push_back(r);
-  }
-  auto& first = ranges.back();
-  if (first.contains(r)) return;
-  if (r.end >= first.start) {
-    first.start = r.start;
-  } else {
-    ranges.push_back(r);
-  }
-}
-
-// Return true if one of the ranges in this interval includes pos
-bool Interval::covers(unsigned pos) const {
-  if (pos < start() || pos >= end()) return false;
-  for (auto r : ranges) {
-    if (pos < r.start) return false;
-    if (pos < r.end) return true;
-  }
-  return false;
-}
-
-// Return true if there is a use position at pos
-bool Interval::usedAt(unsigned pos) const {
-  if (pos < start() || pos > end()) return false;
-  for (auto& u : uses) if (u.pos == pos) return true;
-  return false;
-}
-
-// Return the interval which has a use position at pos
-Interval* Interval::childAt(unsigned pos) {
-  assert(!isChild());
-  for (auto ivl = this; ivl; ivl = ivl->next) {
-    if (pos < ivl->start()) return nullptr;
-    if (ivl->usedAt(pos)) return ivl;
-  }
-  return nullptr;
-}
-
-// return the next intersection point between this and ivl, or MAX_UINT32
-// if they never intersect.
-unsigned Interval::nextIntersect(Interval* ivl) const {
-  assert(!ranges.empty() && !ivl->ranges.empty());
-  auto r1 = ranges.begin(), e1 = ranges.end();
-  auto r2 = ivl->ranges.begin(), e2 = ivl->ranges.end();
-  for (;;) {
-    if (r1->start < r2->start) {
-      if (r2->start < r1->end) return r2->start;
-      if (++r1 == e1) return kMaxPos;
-    } else {
-      if (r1->start < r2->end) return r1->start;
-      if (++r2 == e2) return kMaxPos;
-    }
-  }
-  return kMaxPos;
-}
-
-// Split this interval at pos and return the rest.  Pos must be
-// a location that ensures both shorter intervals are nonempty.
-// Pos must also be odd, indicating a position between instructions.
-// If keep_uses is set, uses exactly at the end of the first interval
-// will stay with the first part.
-Interval* Interval::split(unsigned pos, bool keep_uses) {
-  assert(pos > start() && pos < end());
-  auto leader = this->leader();
-  Interval* child = jit::make<Interval>(leader);
-  child->next = next;
-  next = child;
-  // advance r1 to the first range we want in child; maybe split a range.
-  auto r1 = ranges.begin(), r2 = ranges.end();
-  while (r1->end <= pos) r1++;
-  if (pos > r1->start) { // split r at pos
-    child->ranges.push_back(LiveRange(pos, r1->end));
-    r1->end = pos;
-    r1++;
-  }
-  child->ranges.insert(child->ranges.end(), r1, r2);
-  ranges.erase(r1, r2);
-  // advance u1 to the first use position in child, then copy u1..end to child.
-  auto u1 = uses.begin(), u2 = uses.end();
-  if (keep_uses) {
-    while (u1 != u2 && u1->pos <= end()) u1++;
-  } else {
-    while (u1 != u2 && u1->pos < child->start()) u1++;
-  }
-  child->uses.insert(child->uses.end(), u1, u2);
-  uses.erase(u1, u2);
-  assert(checkInvariants() && child->checkInvariants());
-  return child;
-}
-
-// Return the position of the next use of this interval after (or equal to)
-// pos.  If there are no more uses after pos, return MAX.
-unsigned Interval::firstUseAfter(unsigned pos) const {
-  for (auto& u : uses) {
-    if (pos <= u.pos) return u.pos;
-  }
-  return kMaxPos;
-}
-
-unsigned Interval::lastUseBefore(unsigned pos) const {
-  auto prev = 0;
-  for (auto& u : uses) {
-    if (u.pos > pos) return prev;
-    prev = u.pos;
-  }
-  return prev;
-}
-
-// return the position of the first use that requires a register,
-// or kMaxPos if no remaining uses need registers.
-unsigned Interval::firstUse() const {
-  return uses.empty() ? kMaxPos : uses.front().pos;
-}
-
-// Return the register(s) assigned to this interval as a pair.
-RegPair Interval::regs() const {
-  return RegPair(loc.reg(0), loc.reg(1));
-}
-
-//////////////////////////////////////////////////////////////////////////////
-
-XLS::XLS(IRUnit& unit, RegAllocInfo& regs, const Abi& abi)
-  : m_intervals(unit, nullptr)
-  , m_unit(unit)
-  , m_regs(regs)
-  , m_abi(abi)
-  , m_posns(unit, 0)
-  , m_liveIn(unit, LiveSet())
-  , m_edgeCopies(unit, { nullptr, nullptr }) {
-  auto all = abi.unreserved();
-  for (auto r : m_blocked) {
-    m_blocked[r].blocked = true;
-    m_blocked[r].need = 1;
-    m_blocked[r].loc.setReg(r, 0);
-    if (!all.contains(r)) {
-      // r is never available
-      m_blocked[r].add(LiveRange(0, kMaxPos));
-    }
-    m_scratch[r].scratch = true;
-    m_scratch[r].need = 1;
-    m_scratch[r].loc.setReg(r, 0);
-  }
-}
-
-XLS::~XLS() {
-  for (auto ivl : m_intervals) {
-    for (Interval* next; ivl; ivl = next) {
-      next = ivl->next;
-      jit::destroy(ivl);
-    }
-  }
-}
-
-// Split critical edges, remove dead predecessor edges, and put blocks
-// in a sutiable order.
-void XLS::prepareBlocks() {
-  splitCriticalEdges(m_unit);
-  m_blocks = rpoSortCfg(m_unit);
-}
-
-// compute the position number for each instruction.  Instructions are
-// assigned even positions; shuffles may later occupy inbetween positions.
-void XLS::computePositions() {
-  m_insts.resize(2 * (m_unit.numInsts() + m_unit.numBlocks()));
-  unsigned pos = 0;
-  for (auto b : m_blocks) {
-    auto& front = b->front();
-    if (front.numSrcs() > 0) {
-      // ensure no uses at block-start so livein ranges are nonempty
-      b->prepend(m_unit.gen(DefLabel, front.marker()));
-    }
-    for (auto& inst : *b) {
-      m_insts[pos] = &inst;
-      m_posns[inst] = pos;
-      pos += 2;
-    }
-  }
-}
-
-// Return the reg mask that corresponds to a constraint, and deal with
-// the EvalHHIRAllocSIMDRegs option.  Only disable SIMD for constraints
-// that have some other option. (Don't create empty allow sets).
-// The check is intentionally here instead of in src/dstConstraint(), so
-// the latter can directly reflect the instruction-selection source code
-// in CodeGenerator.
-RegSet constrainedRegs(Constraint c, const Abi& abi) {
-  auto regs = RegSet();
-  if (c & Constraint::GP) regs |= abi.gpUnreserved;
-  if (c & Constraint::SIMD) {
-    if (regs.empty() || RuntimeOption::EvalHHIRAllocSIMDRegs) {
-      regs |= abi.simdUnreserved;
-    }
-  }
-  return regs;
-}
-
-// Reduce the allow and prefer sets according to this particular use
-void srcConstraints(Interval* ivl, const Abi& abi, Constraint constraint) {
-  auto allow = constrainedRegs(constraint, abi);
-  ivl->allow &= allow;
-  ivl->prefer &= allow;
-  if (!(ivl->allow & abi.simdUnreserved).empty()) {
-    // we allow gp and simd, so prefer just simd
-    ivl->prefer &= abi.simdUnreserved;
-  }
-}
-
-// Reduce the allow and prefer constraints based on this definition
-void dstConstraints(Interval* ivl, const Abi& abi, Constraint constraint) {
-  auto allow = constrainedRegs(constraint, abi);
-  ivl->allow &= allow;
-  ivl->prefer &= allow;
-  if (!(ivl->allow & abi.simdUnreserved).empty()) {
-    // if we allow gp and simd, then prefer just simd
-    ivl->prefer &= abi.simdUnreserved;
-  }
-  if (ivl->tmp->numWords() == 2 && !(ivl->allow & ivl->prefer).empty()) {
-    // we prefer simd, but allow gp and simd, so restrict allow to just
-    // simd to avoid (simd)<->(gpr,gpr) shuffles.
-    ivl->allow = ivl->prefer;
-  }
-}
-
-// if this use is an input to a jump (phi), provide a hint to encourage
-// using the same register as the corresponding phi dest.
-Use XLS::coalesceSrc(unsigned pos, const IRInstruction& inst, unsigned i) {
-  if (inst.is(Jmp)) {
-    return Use{pos, Use::kPhiSrc, i};
-  }
-  return Use{pos};
-}
-
-// return the ssatmp to use to use for a copy hint
-Use XLS::coalesceDst(unsigned pos, const IRInstruction& inst, unsigned i) {
-  if (inst.isPassthrough()) {
-    // this use is a copy def; the hint is the the src
-    return Use{pos, inst.getPassthroughValue()};
-  }
-  if (inst.is(DefLabel)) {
-    // this use is a phi dest; the hint lets find each of the srcs
-    return Use{pos, Use::kPhiDst, i};
-  }
-  return Use{pos};
-}
-
-// build intervals in one pass by walking the block list backwards.
-// no special handling is needed for goto/label (phi) instructions because
-// they use/define tmps in the expected locations.
-void XLS::buildIntervals() {
-  unsigned min_need = 0;
-  auto& backend = mcg->backEnd();
-  for (auto blockIt = m_blocks.end(); blockIt != m_blocks.begin();) {
-    auto block = *--blockIt;
-    // compute initial live set from liveIn[succsessors]
-    LiveSet live;
-    if (auto taken = block->taken()) live |= m_liveIn[taken];
-    if (auto next  = block->next())  live |= m_liveIn[next];
-    // initialize live range for each live tmp to whole block
-    auto blockStart = m_posns[block->front()];
-    auto blockEnd = m_posns[block->back()] + 2;
-    live.forEach([&](uint32_t id) {
-      m_intervals[id]->add(LiveRange(blockStart, blockEnd));
-    });
-    for (auto instIt = block->end(); instIt != block->begin();) {
-      auto& inst = *--instIt;
-      auto pos = m_posns[inst];
-      unsigned dst_need = 0;
-      auto& inst_regs = m_regs[inst];
-      for (unsigned i = 0, n = inst.numDsts(); i < n; ++i) {
-        auto d = inst.dst(i);
-        auto dest = m_intervals[d];
-        auto constraint = dstConstraint(inst, i);
-        if (!live[d]) {
-          // dest is not live; give it a register anyway.
-          if (d->numWords() == 0) continue;
-          if (constraint.reg() != InvalidReg) {
-            inst_regs.dst(i).setReg(constraint.reg(), 0);
-            continue;
-          }
-          if (constraint & Constraint::VOID) {
-            continue; // unused dest will be InvalidReg
-          }
-          m_intervals[d] = dest = jit::make<Interval>();
-          dest->add(LiveRange(pos, pos + 1));
-          dest->tmp = d;
-          dest->need = d->numWords();
-          dest->allow = dest->prefer = m_abi.unreserved();
-        } else {
-          // adjust start pos for live intervals defined by this instruction
-          dest->ranges.back().start = pos;
-          live.erase(d);
-        }
-        dst_need += dest->need;
-        auto hint = backend.precolorDst(inst, i);
-        if (hint.first != InvalidReg) {
-          dest->addUse({pos, hint});
-        } else if (RuntimeOption::EvalHHIREnableCoalescing) {
-          dest->addUse(coalesceDst(pos, inst, i));
-        } else {
-          dest->addUse(Use{pos});
-        }
-        dstConstraints(dest, m_abi, constraint);
-      }
-      min_need = std::max(min_need, dst_need);
-      if (inst.isNative()) {
-        if (RuntimeOption::EvalHHIREnableCalleeSavedOpt) {
-          auto scratch = m_abi.gpUnreserved - m_abi.calleeSaved;
-          scratch.forEach([&](PhysReg r) {
-            // Add an empty range to caller-saved intervals that will
-            // intersect with ordinary intervals that span calls,
-            // causing them to prefer callee-saved registers.  This is
-            // the only situation where an empty range is valid.
-            m_scratch[r].add(LiveRange(pos, pos));
-          });
-        }
-      }
-      if (inst.is(Call, CallArray, ContEnter)) {
-        // block all registers at php callsites.
-        m_abi.unreserved().forEach([&](PhysReg r) {
-          m_blocked[r].add(LiveRange(pos, pos + 1));
-        });
-      }
-      // add live ranges for tmps used by this inst
-      unsigned src_need = 0;
-      for (unsigned i = 0, n = inst.numSrcs(); i < n; ++i) {
-        auto s = inst.src(i);
-        auto constraint = srcConstraint(inst, i);
-        if (constraint == Constraint::IMM) continue;
-        if (s->isConst() && (constraint & Constraint::IMM)) continue;
-        if (s->isConst()) {
-          TRACE(1, "xls-const-src %s %u\n", opcodeName(inst.op()), i);
-        }
-        auto need = s->numWords();
-        if (need == 0) continue; //XXX problematic for InitNull|UninitNull
-        if (constraint.reg() != InvalidReg) {
-          inst_regs.src(i).setReg(constraint.reg(), 0);
-          continue;
-        }
-        auto src = m_intervals[s];
-        if (!src) m_intervals[s] = src = jit::make<Interval>();
-        src->add(LiveRange(blockStart, pos));
-        auto hint = backend.precolorSrc(inst, i);
-        if (hint.first != InvalidReg) {
-          src->addUse({pos, hint});
-        } else if (RuntimeOption::EvalHHIREnableCoalescing) {
-          src->addUse(coalesceSrc(pos, inst, i));
-        } else {
-          src->addUse(Use{pos});
-        }
-        if (!src->tmp) {
-          src->tmp = s;
-          src->need = need;
-          src->allow = src->prefer = m_abi.unreserved();
-        }
-        srcConstraints(src, m_abi, constraint);
-        src_need += src->need;
-        live.add(s);
-      }
-      min_need = std::max(min_need, src_need);
-    }
-    m_liveIn[block] = live;
-    // if this block is a loop header, add a live range that covers
-    // the whole loop, to each interval live-into this block.
-    block->forEachPred([&](Block* pred) {
-      auto predEnd = m_posns[pred->back()] + 2;
-      if (predEnd > blockStart) {
-        live.forEach([&](uint32_t id) {
-          auto ivl = m_intervals[id];
-          ivl->add(LiveRange{blockStart, predEnd});
-        });
-      }
-    });
-  }
-  // Implement stress mode by blocking NumFreeRegs more than minimum needed.
-  min_need += RuntimeOption::EvalHHIRNumFreeRegs;
-  assert(min_need >= RuntimeOption::EvalHHIRNumFreeRegs); // no wraparound.
-  for (auto r : m_blocked) {
-    auto& blocked = m_blocked[r];
-    if (!blocked.empty() && blocked.start() == 0) continue;
-    // r is at least partially available
-    if (min_need > 0) {
-      min_need--;
-      std::reverse(blocked.ranges.begin(), blocked.ranges.end());
-    } else {
-      blocked.add(LiveRange(0, kMaxPos));
-      assert(blocked.ranges.size() == 1);
-    }
-  }
-  for (auto r : m_scratch) {
-    auto& scratch = m_scratch[r];
-    std::reverse(scratch.ranges.begin(), scratch.ranges.end());
-  }
-  // We built the use list of each interval by appending.  Now reverse those
-  // lists so they are in forwards order.
-  for (auto ivl : m_intervals) {
-    if (!ivl) continue;
-    std::reverse(ivl->uses.begin(), ivl->uses.end());
-    std::reverse(ivl->ranges.begin(), ivl->ranges.end());
-  }
-  if (dumpIREnabled(kRegAllocLevel)) {
-    print("after building intervals");
-  }
-}
-
-// comparison function for pending priority queue. std::priority_queue
-// requies a less operation, but sorts the heap highest-first; we
-// need the opposite (lowest-first), so use greater-than.
-bool XLS::Compare::operator()(const Interval* i1, const Interval* i2) {
-  return i1->start() > i2->start();
-}
-
-// insert interval into pending list in order of start position
-void XLS::enqueue(Interval* ivl) {
-  assert(ivl->checkInvariants() && !ivl->handled());
-  assert(ivl->start() >= m_frontier);
-  m_pending.push(ivl);
-}
-
-// Assign the next available spill slot to interval
-void XLS::assignSpill(Interval* ivl) {
-  assert(!ivl->blocked && !ivl->scratch && ivl->isChild());
-  assert(ivl->need == 1 || ivl->need == 2);
-  assert(ivl->firstUse() > ivl->end());
-  auto leader = ivl->leader();
-  if (!leader->spill.spilled()) {
-    if (ivl->need == 1) {
-      leader->spill.setSlot(0, m_nextSpill++);
-    } else {
-      if (!PhysLoc::isAligned(m_nextSpill)) m_nextSpill++;
-      leader->spill.setSlot(0, m_nextSpill++);
-      leader->spill.setSlot(1, m_nextSpill++);
-    }
-    if (m_nextSpill > NumPreAllocatedSpillLocs) {
-      TRACE(1,"xls-punt TooManySpills\n");
-      PUNT(LinearScan_TooManySpills);
-    }
-  }
-  ivl->loc = leader->spill;
-}
-
-// Assign one or both of the registers in r to this interval.
-void XLS::assignReg(Interval* ivl, RegPair r) {
-  assert(!ivl->blocked && !ivl->scratch);
-  auto r0 = PhysReg(r.first);
-  auto r1 = PhysReg(r.second);
-  if (ivl->need == 1) {
-    ivl->loc.setReg(r0, 0);
-  } else {
-    if (r0.isSIMD()) {
-      ivl->loc.setRegFullSIMD(r0);
-    } else if (r1.isSIMD()) {
-      ivl->loc.setRegFullSIMD(r1);
-    } else {
-      assert(r0 != r1);
-      ivl->loc.setReg(r0, 0);
-      ivl->loc.setReg(r1, 1);
-    }
-  }
-  // now ivl has a register, so put it in active list.
-  m_active.push_back(ivl);
-}
-
-// initialize the positions array with maximal use positions.
-RegPositions::RegPositions() {
-  for (auto r : posns) posns[r] = kMaxPos;
-}
-
-// Find the register used furthest in the future, but only consider registers
-// in the given set.  Also return that register's position.
-unsigned
-RegPositions::find1(RegSet allow, RegPair& regs) const {
-  unsigned max1 = 0;
-  PhysReg r1 = *posns.begin();
-  allow.forEach([&](PhysReg r) {
-    if (posns[r] > max1) {
-      r1 = r;
-      max1 = posns[r];
-    }
-  });
-  regs = { r1, InvalidReg };
-  return max1;
-}
-
-// Find the two registers used furthest in the future, but only
-// consider registers in the given set.  Return the registers, and
-// their minimum position
-unsigned
-RegPositions::find2(RegSet allow, RegPair& regs) const {
-  unsigned max1 = 0, max2 = 0;
-  PhysReg r1 = *posns.begin(), r2 = *posns.begin();
-  allow.forEach([&](PhysReg r) {
-    if (posns[r] > max2) {
-      if (posns[r] > max1) {
-        r2 = r1; max2 = max1;
-        r1 = r; max1 = posns[r];
-      } else {
-        r2 = r; max2 = posns[r];
-      }
-    }
-  });
-  assert(max1 >= max2);
-  regs = { r1, r2 };
-  return r1 != r2 ? max2 : 0;
-}
-
-unsigned
-RegPositions::find(Interval* ivl, RegSet allow, RegPair& regs) const {
-  return ivl->need == 1 ? find1(allow, regs) : find2(allow, regs);
-}
-
-// Return the [lowest] position of the registers in regs
-unsigned RegPositions::getPos(Interval* ivl, RegPair regs) const {
-  return ivl->need == 1 ? posns[regs.first] :
-         regs.first == regs.second ? 0 : // only found one register
-         std::min(posns[regs.first], posns[regs.second]);
-}
-
-// Update the position associated with the registers assigned to ivl,
-// to the minimum of pos and the existing position.
-unsigned RegPositions::setPos(Interval* ivl, unsigned pos) {
-  assert(ivl->loc.numAllocated() >= 1);
-  auto r0 = ivl->loc.reg(0);
-  auto minpos = posns[r0] = std::min(pos, posns[r0]);
-  if (ivl->loc.numAllocated() == 2) {
-    auto r1 = ivl->loc.reg(1);
-    posns[r1] = std::min(pos, posns[r1]);
-    minpos = std::min(minpos, posns[r1]);
-  }
-  return minpos;
-}
-
-// Return the closest valid split position on or before pos.
-unsigned nearestSplitBefore(unsigned pos) {
-  return pos == 0 || pos % 2 == 1 ? pos : pos - 1;
-}
-
-// In order to use a hint, it needs enough registers, in the allow set,
-// which are free for the whole lifetime of current.
-bool isUsable(RegPair hint, Interval* current, const RegPositions& free_until) {
-  if (current->need == 1) {
-    if (hint.first == InvalidReg || !current->allow.contains(hint.first)) {
-      return false;
-    }
-  } else {
-    if (hint.first == InvalidReg || hint.second == InvalidReg ||
-        !current->allow.contains(hint.first) ||
-        !current->allow.contains(hint.second)) {
-      return false;
-    }
-  }
-  auto until_pos = free_until.getPos(current, hint);
-  return until_pos >= current->end();
-}
-
-// Return the first usable hint from all the uses in this interval.
-// If we can't use the first one, keep looking; a later one might
-// not be as good, but still could be better than giving up.
-RegPair XLS::firstHint(Interval* current, const RegPositions& free_until) {
-  if (!RuntimeOption::EvalHHIREnablePreColoring &&
-      !RuntimeOption::EvalHHIREnableCoalescing) return InvalidRegPair;
-  // search the copy interval for a register hint at pos
-  auto search = [&](Interval* copy, unsigned pos) -> RegPair {
-    for (auto ivl = copy; ivl; ivl = ivl->next) {
-      if (pos == ivl->end() && ivl->loc.hasReg(0)) {
-        return ivl->loc.pair();
-      }
-    }
-    return InvalidRegPair;
-  };
-  auto searchPreds = [&](Block* block, unsigned index) {
-    auto hint = InvalidRegPair;
-    block->forEachSrc(index, [&](IRInstruction* jmp, SSATmp* src) {
-      if (!isUsable(hint, current, free_until)) {
-        hint = search(m_intervals[src], m_posns[jmp]);
-      }
-    });
-    return hint;
-  };
-  for (auto u : current->uses) {
-    auto hint = InvalidRegPair;
-    switch (u.kind) {
-      case Use::kNone:
-        continue;
-      case Use::kReg:
-        hint = u.regHint;
-        break;
-      case Use::kCopy:
-        hint = search(m_intervals[u.srcId], u.pos);
-        break;
-      case Use::kPhiSrc:
-        hint = searchPreds(m_insts[u.pos]->taken(), u.phiIndex);
-        break;
-      case Use::kPhiDst:
-        hint = searchPreds(m_insts[u.pos]->block(), u.phiIndex);
-        break;
-    }
-    if (isUsable(hint, current, free_until)) {
-      return hint;
-    }
-  }
-  return InvalidRegPair;
-}
-
-// Allocate one register for the current interval.
-// First try to find a register to assign to current, or its first part.
-// If none can be found, tail-call to allocBlocked which will spill
-// something, maybe current or another interval.
-//
-// SSA form guarantees that two SSA intervals that intersect,
-// must intersect at one or the other's start position.  Current
-// does not intersect with inactive intervals at current->start(),
-// and inactive intervals must have started earlier.  Thus they
-// cannot intersect.  But we can only skip the intersection test
-// for the original interval -- split intervals no longer have
-// the SSA property.
-void XLS::allocOne(Interval* current) {
-  assert(!current->handled());
-  if (current->isChild() && current->start() % 2 == 0) {
-    // TODO: #3098697 only spill if it's not on a block boundary.
-    assert(current->firstUse() > current->start());
-    return spill(current);
-  }
-  RegPositions until1; // free-until, ignoring scratch
-  RegPositions until2; // free-until, including scratch
-  for (auto ivl : m_active) {
-    if (ivl->scratch) {
-      until2.setPos(ivl, 0);
-    } else {
-      until1.setPos(ivl, 0);
-      until2.setPos(ivl, 0);
-    }
-  }
-  for (auto ivl : m_inactive) {
-    auto intersectPos = current->nextIntersect(ivl);
-    if (ivl->scratch) {
-      until2.setPos(ivl, intersectPos);
-    } else {
-      auto pos = until1.setPos(ivl, intersectPos);
-      until2.setPos(ivl, pos);
-    }
-  }
-
-  // Try to get a hinted register
-  auto hint = firstHint(current, until2);
-  if (hint.first != InvalidReg) {
-    assert(isUsable(hint, current, until2));
-    return assignReg(current, hint);
-  }
-
-  // Try to get a preferred-non scratch register
-  RegPair r;
-  auto until_pos = until2.find(current, current->prefer, r);
-  if (until_pos >= current->end()) {
-    // got one for all of current
-    return assignReg(current, r);
-  }
-  // find the register(s) that are free for the longest time.
-  until_pos = until2.find(current, current->allow, r);
-  if (until_pos >= current->end()) {
-    // got register for all of current
-    return assignReg(current, r);
-  }
-  // try prefer set again but ignore scratch register conflicts
-  until_pos = until1.find(current, current->prefer, r);
-  if (until_pos >= current->end()) {
-    // got one for all of current
-    return assignReg(current, r);
-  }
-  // try allow set again but ignore scratch register conflicts
-  until_pos = until1.find(current, current->allow, r);
-  if (until_pos >= current->end()) {
-    // got register for all of current
-    return assignReg(current, r);
-  }
-  if (until_pos <= current->start()) {
-    // nothing free for any of current
-    return allocBlocked(current);
-  }
-  // register is free for part of current; assign register and enqueue
-  // the remaining part.
-  auto prev_use = current->lastUseBefore(until_pos);
-  auto min_split = std::max(prev_use, current->start() + 1);
-  auto max_split = until_pos;
-  assert(min_split <= max_split);
-  auto split_pos = std::max(min_split, max_split); // todo: find good spot
-  // got register for first part of current
-  enqueue(current->split(split_pos, true));
-  assignReg(current, r);
-}
-
-// When all registers are in use, find a good interval to split and spill,
-// which could be the current interval.  When an interval is split and the
-// second part is spilled, possibly split the second part again before the
-// next use-pos that requires a register, and enqueue the third part.
-void XLS::allocBlocked(Interval* current) {
-  RegPositions used;
-  RegPositions blocked;
-  auto const cur_start = current->start();
-  // compute next use of active registers, so we can pick the furthest one
-  for (auto ivl : m_active) {
-    if (ivl->blocked) {
-      blocked.setPos(ivl, 0);
-      used.setPos(ivl, 0);
-    } else {
-      used.setPos(ivl, ivl->firstUseAfter(cur_start));
-    }
-  }
-  // compute next intersection/use of inactive regs to find whats free longest
-  for (auto ivl : m_inactive) {
-    auto intersectPos = current->nextIntersect(ivl);
-    if (intersectPos == kMaxPos) continue;
-    if (ivl->blocked) {
-      auto pos = blocked.setPos(ivl, intersectPos);
-      used.setPos(ivl, pos);
-    } else {
-      used.setPos(ivl, ivl->firstUseAfter(cur_start));
-    }
-  }
-  // choose the best victim register(s) to spill
-  RegPair r;
-  auto used_pos = used.find(current, current->allow, r);
-  if (used_pos < current->firstUse()) {
-    // all other intervals are used before current's first register-use
-    return spill(current);
-  }
-  auto block_pos = blocked.getPos(current, r);
-  if (block_pos < current->end()) {
-    auto prev_use = current->lastUseBefore(block_pos);
-    auto min_split = std::max(prev_use, cur_start + 1);
-    auto max_split = block_pos;
-    assert(cur_start < min_split && min_split <= max_split);
-    auto split_pos = std::max(min_split, max_split);
-    enqueue(current->split(split_pos, true));
-  }
-  spillOthers(current, r);
-  assignReg(current, r);
-}
-
-// return true if r1 and r2 have any registers in common
-bool conflict(RegPair r1, RegPair r2) {
-  assert(r1.first != InvalidReg && r2.first != InvalidReg);
-  assert(r1.first != r1.second && r2.first != r2.second);
-  return r1.first == r2.first ||
-         r1.first == r2.second ||
-         (r1.second != InvalidReg &&
-          (r1.second == r2.first || r1.second == r2.second));
-}
-
-// split ivl at pos and spill the second part.  If pos is too close
-// to ivl->start(), spill all of ivl.
-void XLS::spillAfter(Interval* ivl, unsigned pos) {
-  auto split_pos = nearestSplitBefore(pos);
-  auto tail = split_pos <= ivl->start() ? ivl : ivl->split(split_pos);
-  spill(tail);
-}
-
-// Spill ivl from its start until its first register use.  If there
-// is no use, spill the entire interval.  Otherwise split the
-// interval just before the use, and enqueue the second part.
-void XLS::spill(Interval* ivl) {
-  unsigned first_use = ivl->firstUse();
-  if (first_use <= ivl->end()) {
-    auto split_pos = nearestSplitBefore(first_use);
-    if (split_pos <= ivl->start()) {
-      TRACE(1,"xls-punt RegSpill\n");
-      PUNT(RegSpill); // cannot split before first_use
-    }
-    enqueue(ivl->split(split_pos));
-  }
-  assert(ivl->uses.size() == 0);
-  if (!isDefConst(ivl)) assignSpill(ivl);
-}
-
-// remove the element at list[i] by moving the last element down.
-void XLS::erase(IntervalList& list, IntervalList::iterator i) {
-  *i = list.back();
-  list.pop_back();
-}
-
-// Split and spill other intervals that conflict with current for
-// register r, at current->start().  If necessary, split the victims
-// again before their first use position that requires a register.
-void XLS::spillOthers(Interval* current, RegPair r) {
-  auto cur_start = current->start();
-  for (auto i = m_active.begin(); i != m_active.end();) {
-    auto other = *i;
-    if (other->scratch || !conflict(r, other->regs())) {
-      i++; continue;
-    }
-    erase(m_active, i);
-    spillAfter(other, cur_start);
-  }
-  for (auto i = m_inactive.begin(); i != m_inactive.end();) {
-    auto other = *i;
-    if (other->scratch || !conflict(r, other->regs())) {
-      i++; continue;
-    }
-    auto intersect = current->nextIntersect(other);
-    if (intersect >= current->end()) {
-      i++; continue;
-    }
-    erase(m_inactive, i);
-    spillAfter(other, cur_start);
-  }
-}
-
-// Update active/inactive sets based on pos
-void XLS::update(unsigned pos) {
-  m_frontier = pos;
-  // check for intervals in active that are expired or inactive
-  for (auto i = m_active.begin(); i != m_active.end();) {
-    auto ivl = *i;
-    if (ivl->end() <= pos) {
-      // done with ivl; remove interval from active list
-      erase(m_active, i);
-    } else if (!ivl->covers(pos)) {
-      // move ivl from active to inactive
-      erase(m_active, i);
-      m_inactive.push_back(ivl);
-    } else {
-      i++;
-    }
-  }
-  // check for intervals that are expired or active
-  for (auto i = m_inactive.begin(); i != m_inactive.end();) {
-    auto ivl = *i;
-    if (ivl->end() <= pos) {
-      // done with ivl; remove interval from inactive list
-      erase(m_inactive, i);
-    } else if (ivl->covers(pos)) {
-      // move ivl from inactive to active
-      erase(m_inactive, i);
-      m_active.push_back(ivl);
-    } else {
-      i++;
-    }
-  }
-}
-
-// assign registers to intervals, split & spill where needed.
-void XLS::walkIntervals() {
-  // fill the pending queue with nonempty intervals in order of start position
-  for (auto ivl : m_intervals) {
-    if (!ivl) continue;
-    m_orig++;
-    if (isDefConst(ivl)) {
-      spill(ivl);
-    } else {
-      enqueue(ivl);
-    }
-  }
-  for (auto r : m_scratch) {
-    if (!m_scratch[r].empty()) m_inactive.push_back(&m_scratch[r]);
-  }
-  for (auto r : m_blocked) {
-    if (!m_blocked[r].empty()) m_inactive.push_back(&m_blocked[r]);
-  }
-  while (!m_pending.empty()) {
-    Interval* current = m_pending.top();
-    m_pending.pop();
-    update(current->start());
-    allocOne(current);
-    assert(isDefConst(current) ||
-           (current->handled() && current->loc.numWords() == current->need));
-  }
-  if (dumpIREnabled(kRegAllocLevel)) {
-    dumpIntervals();
-    print("after walking intervals");
-  }
-}
-
-// Assign PhysLocs (registers or spill slots) to every src and dst ssatmp
-void XLS::assignLocations() {
-  for (auto b : m_blocks) {
-    for (auto& inst : *b) {
-      auto pos = m_posns[inst];
-      auto& inst_regs = m_regs[inst];
-      for (unsigned i = 0, n = inst.numSrcs(); i < n; i++) {
-        auto ivl = m_intervals[inst.src(i)];
-        if (ivl) {
-          ivl = ivl->childAt(pos);
-          if (ivl) inst_regs.src(i) = ivl->loc;
-        }
-      }
-      for (unsigned i = 0, n = inst.numDsts(); i < n; i++) {
-        auto ivl = m_intervals[inst.dst(i)];
-        if (ivl) inst_regs.dst(i) = ivl->loc;
-      }
-    }
-  }
-}
-
-// Add a copy of tmp from rs to rd to the Shuffle instruction shuffle,
-// if it exists.  Otherwise, create a new one and insert it at pos in block b.
-void XLS::insertCopy(Block* b, Block::iterator pos, IRInstruction* &shuffle,
-                     SSATmp* src, const PhysLoc& rs, const PhysLoc& rd) {
-  assert(rs != rd);
-  unsigned i;
-  if (shuffle) {
-    // already have shuffle here
-    i = shuffle->numSrcs();
-    shuffle->addCopy(m_unit, src, rd);
-  } else {
-    i = 0;
-    auto cap = 1;
-    auto dests = new (m_unit.arena()) PhysLoc[cap];
-    dests[0] = rd;
-    auto& marker = pos != b->end() ? pos->marker() : b->back().marker();
-    shuffle = m_unit.gen(Shuffle, marker, ShuffleData(dests, 1, cap), src);
-    b->insert(pos, shuffle);
-  }
-  auto& shuffle_regs = m_regs[shuffle];
-  shuffle_regs.resize(i + 1);
-  shuffle_regs.src(i) = rs;
-  auto inst_pos = m_posns[*pos];
-  m_posns[shuffle] = pos->op() == Shuffle ? inst_pos : inst_pos - 1;
-  if (src->isConst()) m_ldconst++;
-  else if (rd.spilled()) m_spills++;
-  else if (rs.spilled()) m_reloads++;
-  else m_copies++;
-}
-
-// Insert a spill-store Shuffle after the instruction that defines ivl->tmp.
-// If the instruction is a branch, do the store on the edge to the next block.
-void XLS::insertSpill(Interval* ivl) {
-  assert(!ivl->isChild() && ivl->start() % 2 == 0);
-  auto inst = ivl->tmp->inst();
-  if (inst->isBlockEnd()) {
-    auto succ = inst->next();
-    auto iter = succ->skipHeader();
-    auto& shuffle = m_edgeCopies[inst->block()].first;
-    insertCopy(succ, iter, shuffle, ivl->tmp, ivl->loc, ivl->spill);
-  } else {
-    assert(inst != &inst->block()->back()); // can't be last in block
-    auto block = inst->block();
-    auto iter = block->iteratorTo(inst);
-    auto& shuffle = m_insts[ivl->start() + 1];
-    insertCopy(block, ++iter, shuffle, ivl->tmp, ivl->loc, ivl->spill);
-  }
-}
-
-/*
- * Insert Shuffle instructions.  Each Shuffle at a given position implements
- * a parallel copy: all sources are read before any destination is written.
- * 1. If any part of interval was spilled, insert a copy (store) to the spill
- * slot after the defining instruction.
- * 2. For intervals split in the middle of a block, connect the two
- * sub-intervals by inserting a copy at the split point.  "middle" means any
- * program point after the first instruction and before the last instruction
- * in the block.  Intervals that were split on block boundaries are handled
- * in step 3.
- * 3. (resolveSplits) When a sub-interval is live at the start of a block
- * (i.e. live-in), and a different sub-interval was live at the end of the
- * predecessor, insert a copy on the edge connecting the two blocks.  If that
- * edge is a critical edge, split it first.
- * 4. Resolve "phi"s by inserting copies on Jmp->DefLabel edges.
- * These are similar to case 3, except they are two different intervals
- * logically connected by the phi (Jmp->DefLabel) copy.  This is done at the
- * same time as resolving edges.
- */
-
-// Insert spills and copies that connect sub-intervals that were split between
-// instructions
-void XLS::resolveSplits() {
-  if (dumpIREnabled(kRegAllocLevel)) dumpIntervals();
-  for (auto i1 : m_intervals) {
-    if (!i1) continue;
-    m_final++;
-    if (i1->spill.spilled()) insertSpill(i1);
-    for (auto i2 = i1->next; i2; i1 = i2, i2 = i2->next) {
-      m_final++;
-      auto pos = i2->start();
-      if (i1->end() != pos) continue; // spans lifetime hole
-      if (i1->loc == i2->loc) continue; // no copy necessary
-      if (i2->loc.spilled() || !i2->loc.numAllocated()) continue; // i2 spilled
-      if (pos % 2 == 0) {
-        // even position requiring a copy must be on edge
-        assert(pos >= 2 && m_insts[pos - 2]->block() != m_insts[pos]->block());
-      } else {
-        // odd position
-        auto inst1 = m_insts[pos-1];
-        auto inst2 = m_insts[pos+1];
-        auto block = inst2->block();
-        if (inst1->block() != block) continue; // copy is on edge
-        insertCopy(block, block->iteratorTo(inst2), m_insts[pos],
-                   i1->tmp, i1->loc, i2->loc);
-      }
-    }
-  }
-}
-
-// Insert copies on control-flow edges, and turn Jmps into Shuffles
-void XLS::resolveEdges() {
-  const PhysLoc invalid_loc;
-  for (auto succ : m_blocks) {
-    auto& inst2 = succ->front();
-    auto pos2 = m_posns[inst2]; // pos of first inst in succ.
-    succ->forEachPred([&](Block* pred) {
-      assert(pred->back().op() != Shuffle);
-      auto it1 = pred->end();
-      auto& inst1 = *(--it1);
-      auto pos1 = m_posns[inst1]; // pos of last inst in pred
-      if (inst1.op() == Jmp) {
-        // insert copies on each Jmp->DefLabel edge
-        for (unsigned i = 0, n = inst1.numSrcs(); i < n; ++i) {
-          auto i1 = m_intervals[inst1.src(i)]; // null if const
-          auto i2 = m_intervals[inst2.dst(i)]; // null if unused
-          if (i1) i1 = i1->childAt(pos1);
-          auto loc1 = i1 ? i1->loc : invalid_loc;
-          auto loc2 = i2 ? i2->loc : invalid_loc;
-          if (loc1 == loc2) continue;
-          auto& shuffle = m_edgeCopies[pred].second; // taken edge
-          insertCopy(pred, it1, shuffle, inst1.src(i), loc1, loc2);
-        }
-      }
-      m_liveIn[succ].forEach([&](uint32_t id) {
-        auto ivl = m_intervals[id];
-        resolveFlow(ivl, pred, succ, pos1, pos2);
-      });
-    });
-  }
-  if (dumpIREnabled(kRegAllocLevel)) {
-    print("after resolving intervals");
-  }
-}
-
-void XLS::resolveFlow(Interval* parent, Block* pred, Block* succ,
-                      unsigned pos1, unsigned pos2) {
-  Interval* i1 = nullptr;
-  Interval* i2 = nullptr;
-  for (auto ivl = parent; ivl && !(i1 && i2); ivl = ivl->next) {
-    if (ivl->covers(pos1)) i1 = ivl;
-    if (ivl->covers(pos2)) i2 = ivl;
-  }
-  if (i2->loc.spilled() || i1->loc == i2->loc || i2->loc.numAllocated() == 0) {
-    // if i2 target is a spill loc, equal to i1, or unallocated,
-    // then we don't need any copy.  i2 can be unallocated if the tmp is
-    // a constant.
-    return; // nothing to do
-  }
-  auto& shuffle = pred->next() == succ ? m_edgeCopies[pred].first :
-                  m_edgeCopies[pred].second;
-  if (pred->taken() && pred->next()) {
-    // pred has 2+ successors; insert copy at start of succ
-    insertCopy(succ, succ->skipHeader(), shuffle, i1->tmp, i1->loc, i2->loc);
-  } else {
-    // insert copy at end of predecessor
-    insertCopy(pred, pred->backIter(), shuffle, i1->tmp, i1->loc, i2->loc);
-  }
-}
-
-/*
- * Extended Linear Scan is based on Wimmer & Franz "Linear Scan Register
- * Allocation on SSA Form".
- *
- * 1. Sort blocks such that all predecessors of B come before B, except
- * loop-edge predecessors.  Because the input IR is in SSA form, this also
- * implies the definition of each SSATmp comes before all uses.
- *
- * 2. Assign an even numbered position to every instruction.  Uses where
- * inputs are read occur on even positions, and definition where outputs
- * are written occur on odd positions.  We can only insert new instructions
- * after odd positions and before even positions.  Points after even positions
- * and before odd positions are "inside" existing instructions.
- *
- * 3. Create one interval I for each SSATmp T that requires register allocation,
- * by iterating blocks and instructions in reverse order, computing live
- * SSATmps as we go.  Each interval consists of a sorted list of disjoint,
- * live ranges covering the positions where T must be in a register or
- * spill location.  SSATmps that are constants or have forced registers
- * (e.g. VmSp) are skipped.  Because of SSA form, the start position of each
- * interval dominates every live range and use position in the interval.
- *
- * 4. Process intervals in order of start position, maintaining the set of
- * active (live) and inactive (not live, but with live ranges that start
- * after the current interval).  When choosing a register, prefer the one
- * available furthest into the future.  If necessary, split the current
- * interval so the first part gets a register, and enqueue the rest.
- * When no registers are available, choose either the current interval or
- * another one to spill, trying to free up the longest-available register.
- *
- * Split positions must be after an interval's start position, and on or before
- * the chosen split point.  We're free try to choose a good position inbetween,
- * for example block boundaries and cold blocks.
- *
- * 5. Once intervals have been walked and split, every interval has an assigned
- * operand (register or spill location) for all positions where it's alive.
- * visit every instruction and store the position of its sources and
- * destinations in the RegAllocInfo structure that we pass onto CodeGenerator.
- *
- * 6. Splitting creates sub-intervals that are assigned to different registers
- * or spill locations, so we must insert resolving copies at the split
- * positions between intervals that were split in a block, and copies on
- * control-flow edges connecting different sub-intervals.  When more than one
- * copy occurs in a position, they are parallel-copies (all sources read before
- * any dest is written).
- *
- * If any sub-interval was spilled, we a single store is generated after the
- * definition point.  SSA form ensures this position dominates all uses, so
- * therefore it dominates all reloads.
- *
- * Copies for Jmp->DefLabel edges are also converted to Shuffles, which are
- * combined with any other resolving copies on the same edges.
- */
-
-void XLS::allocate() {
-  prepareBlocks();
-  computePositions();
-  buildIntervals();
-  walkIntervals();
-  assignLocations();
-  resolveSplits();
-  resolveEdges();
-  TRACE(1, "orig %u final %u copies %u spills %u reloads %u ldconst %u\n",
-           m_orig, m_final, m_copies, m_spills, m_reloads, m_ldconst);
-  assert(checkRegisters(m_unit, m_regs));
-}
-
-//////////////////////////////////////////////////////////////////////////////
-
-void XLS::dumpIntervals() {
-  unsigned numSplits = 0;
-  for (auto ivl : m_intervals) {
-    if (!ivl) continue;
-    HPHP::Trace::traceRelease("i%-2d %s\n", ivl->id(),
-                              ivl->toString().c_str());
-    for (ivl = ivl->next; ivl; ivl = ivl->next) {
-      numSplits++;
-      HPHP::Trace::traceRelease("    %s\n", ivl->toString().c_str());
-    }
-  }
-  HPHP::Trace::traceRelease("Splits %d Spills %d\n", numSplits, m_nextSpill);
-}
-
-template<class F>
-void forEachInterval(Intervals& intervals, F f) {
-  for (auto ivl : intervals) {
-    if (ivl) f(ivl);
-  }
-}
-
-enum Mode { Light, Heavy };
-template<class Pred>
-const char* draw(Interval* parent, unsigned pos, Mode m, Pred covers) {
-                               // Light     Heavy
-  static const char* top[]    = { "\u2575", "\u2579" };
-  static const char* bottom[] = { "\u2577", "\u257B" };
-  static const char* both[]   = { "\u2502", "\u2503" };
-  static const char* empty[]  = { " ", " " };
-  auto f = [&](unsigned pos) {
-    for (auto ivl = parent; ivl; ivl = ivl->next) {
-      if (covers(ivl, pos)) return true;
-    }
-    return false;
-  };
-
-  auto s = f(pos);
-  auto d = pos%2 == 1 ? s : f(pos+1);
-  return ( s && !d) ? top[m] :
-         ( s &&  d) ? both[m] :
-         (!s &&  d) ? bottom[m] :
-         empty[m];
-}
-
-void XLS::print(const char* caption) {
-  std::ostringstream str;
-  str << "Intervals " << caption << "\n";
-  forEachInterval(m_intervals, [&] (Interval* ivl) {
-    str << folly::format(" {: <2}", ivl->id());
-  });
-  str << "\n";
-  for (auto& b : m_blocks) {
-    for (auto& i : *b) {
-      auto pos = m_posns[i];
-      forEachInterval(m_intervals, [&] (Interval* ivl) {
-        str << " ";
-        str << draw(ivl, pos, Light, [&](Interval* child, unsigned p) {
-          return child->covers(p);
-        });
-        str << draw(ivl, pos, Heavy, [&](Interval* child, unsigned p) {
-          return child->usedAt(p);
-        });
-      });
-      if (&i == &b->front()) {
-        str << folly::format(" B{: <2}", b->id());
-      } else {
-        str << "    ";
-      }
-      if (i.isNative()) {
-        str << folly::format(" {: <3}-", pos);
-      } else {
-        str << folly::format(" {: <3} ", pos);
-      }
-      jit::printOpcode(str, &i, nullptr);
-      jit::printSrcs(str, &i, &m_regs);
-      if (i.numDsts()) {
-        str << " => ";
-        jit::printDsts(str, &i, &m_regs);
-      }
-      if (&i == &b->back()) {
-        if (auto next = b->next()) {
-          str << folly::format(" next->B{}", next->id());
-        }
-        if (auto taken = b->taken()) {
-          str << folly::format(" taken->B{}", taken->id());
-        }
-      }
-      str << "\n";
-    }
-  }
-  HPHP::Trace::traceRelease("%s\n", str.str().c_str());
-}
-
-std::string Interval::toString() {
-  std::ostringstream out;
-  auto delim = "";
-  if (tmp) {
-    print(out, tmp, &loc);
-  } else {
-    out << loc;
-  }
-  out << " [";
-  for (auto r : ranges) {
-    out << delim << folly::format("{}-{}", r.start, r.end);
-    delim = ",";
-  }
-  out << ") {";
-  delim = "";
-  for (auto u : uses) {
-    out << delim << u.pos;
-    switch (u.kind) {
-      case Use::kNone: break;
-      case Use::kReg:
-        mcg->backEnd().streamPhysReg(out, u.regHint.first);
-        if (u.regHint.second != InvalidReg) {
-          mcg->backEnd().streamPhysReg(out, u.regHint.second);
-        }
-        break;
-      case Use::kCopy:
-        out << 't' << u.srcId;
-        break;
-      case Use::kPhiSrc:
-      case Use::kPhiDst:
-        out << "\u03C6" << u.phiIndex;
-        break;
-    }
-    delim = ",";
-  }
-  out << "}";
-  return out.str();
-}
-
-//////////////////////////////////////////////////////////////////////////////
-
-// Check validity of this interval
-// 1. split-children cannot have more children, nor can the parent
-//    be a child of another interval.
-// 2. live ranges must be nonempty, sorted, and disjoint
-// 3. holes between live ranges must also be non-empty
-// 4. uses must be sorted
-// 5. every use must be inside or just off the end of a range
-// 6. parent and children must all be sorted and disjoint
-bool Interval::checkInvariants() const {
-  assert(!parent || !parent->parent); // 1: no crazy nesting
-  assert(!ranges.empty());
-  DEBUG_ONLY auto min_start = 0;
-  DEBUG_ONLY auto u = uses.begin();
-  for (auto r : ranges) {
-    assert(r.start < r.end); // 2: nonempty range
-    assert(r.start >= min_start); // 2: ranges are sorted
-    min_start = r.end + 1; // 2,3: ranges are disjoint, no empty holes
-    DEBUG_ONLY auto min_use = r.start;
-    while (u != uses.end() && min_use <= u->pos && u->pos <= r.end) {
-      min_use = u->pos; // 4: uses must be sorted
-      u++;
-    }
-  }
-  assert(u == uses.end()); // 4,5: all uses covered
-  assert(!next || next->start() >= end()); // 6: next child is ok.
-  return true;
-}
-}
-//////////////////////////////////////////////////////////////////////////////
-
-// This is the public entry-point
-RegAllocInfo allocateRegs(IRUnit& unit) {
-  Timer _t(Timer::regalloc);
-
-  RegAllocInfo regs(unit);
-  Abi abi = mcg->backEnd().abi();
-  XLS xls(unit, regs, abi);
-  xls.allocate();
-  if (dumpIREnabled()) {
-    printUnit(kRegAllocLevel, unit, " after extended alloc ", &regs,
-              nullptr, nullptr);
-  }
-  return regs;
-}
-
-}}

