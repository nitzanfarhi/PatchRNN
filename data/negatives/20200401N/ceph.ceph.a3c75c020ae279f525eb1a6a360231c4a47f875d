commit a3c75c020ae279f525eb1a6a360231c4a47f875d
Author: sageweil <sageweil@29311d96-e01e-0410-9327-a35deaab8ce9>
Date:   Thu Sep 13 03:57:18 2007 +0000

    various mds tweaks, bug notations from load balancing/failure experiements
    
    git-svn-id: https://ceph.svn.sf.net/svnroot/ceph@1833 29311d96-e01e-0410-9327-a35deaab8ce9

diff --git a/trunk/ceph/mds/CDentry.cc b/trunk/ceph/mds/CDentry.cc
index e0c0650393..415fe986da 100644
--- a/trunk/ceph/mds/CDentry.cc
+++ b/trunk/ceph/mds/CDentry.cc
@@ -163,7 +163,7 @@ void CDentry::mark_clean()
 {
   dout(10) << " mark_clean " << *this << dendl;
   assert(is_dirty());
-  assert(version <= dir->get_version());
+  assert(dir->get_version() == 0 || version <= dir->get_version());  // hmm?
 
   // state+pin
   state_clear(STATE_DIRTY);
diff --git a/trunk/ceph/mds/CDir.cc b/trunk/ceph/mds/CDir.cc
index 8a7fb9387c..7254c05a33 100644
--- a/trunk/ceph/mds/CDir.cc
+++ b/trunk/ceph/mds/CDir.cc
@@ -287,9 +287,9 @@ void CDir::remove_dentry(CDentry *dn)
 
 void CDir::link_remote_inode(CDentry *dn, inodeno_t ino, unsigned char d_type)
 {
-  dout(12) << "link_inode " << *dn << " remote " << ino << dendl;
-
+  dout(12) << "link_remote_inode " << *dn << " remote " << ino << dendl;
   assert(dn->is_null());
+
   dn->set_remote(ino, d_type);
   nitems++;
   dn->clear_dir_offset();
@@ -303,7 +303,7 @@ void CDir::link_remote_inode(CDentry *dn, inodeno_t ino, unsigned char d_type)
 void CDir::link_primary_inode(CDentry *dn, CInode *in)
 {
   dout(12) << "link_primary_inode " << *dn << " " << *in << dendl;
-  assert(!dn->is_remote());
+  assert(dn->is_null());
 
   link_inode_work(dn,in);
   dn->clear_dir_offset();
@@ -362,6 +362,16 @@ void CDir::try_remove_unlinked_dn(CDentry *dn)
   assert(dn->is_null());
   assert(dn->is_dirty());
   
+  /* FIXME: there is a bug in this.  i think new dentries are properly
+     identified.. e.g. maybe a dentry exists, is committed, is removed, is now
+     dirty+null, then reused and mistakenly considered new.. then it is removed, 
+     we remove it here, the dir is fetched, and the dentry exists again.  
+     
+     somethign like that...
+  */
+  return;
+
+
   // no pins (besides dirty)?
   if (dn->get_num_ref() != 1) 
     return;
diff --git a/trunk/ceph/mds/CDir.h b/trunk/ceph/mds/CDir.h
index d267373d5f..f607d47d50 100644
--- a/trunk/ceph/mds/CDir.h
+++ b/trunk/ceph/mds/CDir.h
@@ -309,9 +309,10 @@ private:
 
   // for giving to clients
   void get_dist_spec(set<int>& ls, int auth) {
-    if (( pop_auth_subtree.get(META_POP_IRD).get() > 
-	  g_conf.mds_bal_replicate_threshold)) {
-      //if (!cached_by.empty() && inode.ino > 1) generic_dout(1) << "distributed spec for " << *this << endl;
+    //if (( pop_auth_subtree.get(META_POP_IRD).get() > 
+    //g_conf.mds_bal_replicate_threshold)) {
+    //if (!cached_by.empty() && inode.ino > 1) generic_dout(1) << "distributed spec for " << *this << endl;
+    if (is_rep()) {
       for (map<int,int>::iterator p = replicas_begin();
 	   p != replicas_end(); 
 	   ++p)
diff --git a/trunk/ceph/mds/Locker.cc b/trunk/ceph/mds/Locker.cc
index 4697e2fda6..87d624ec30 100644
--- a/trunk/ceph/mds/Locker.cc
+++ b/trunk/ceph/mds/Locker.cc
@@ -546,7 +546,7 @@ bool Locker::issue_caps(CInode *in)
       if (seq > 0 && 
           !it->second.is_suppress()) {
         dout(7) << "   sending MClientFileCaps to client" << it->first << " seq " << it->second.get_last_seq() << " new pending " << cap_string(it->second.pending()) << " was " << cap_string(before) << dendl;
-        mds->send_message_client(new MClientFileCaps(MClientFileCaps::OP_GRANT,
+        mds->send_message_client_maybe_opening(new MClientFileCaps(MClientFileCaps::OP_GRANT,
 						     in->inode,
 						     it->second.get_last_seq(),
 						     it->second.pending(),
@@ -560,6 +560,16 @@ bool Locker::issue_caps(CInode *in)
 }
 
 
+class C_MDL_RequestInodeFileCaps : public Context {
+  Locker *locker;
+  CInode *in;
+public:
+  C_MDL_RequestInodeFileCaps(Locker *l, CInode *i) : locker(l), in(i) {}
+  void finish(int r) {
+    if (!in->is_auth())
+      locker->request_inode_file_caps(in);
+  }
+};
 
 void Locker::request_inode_file_caps(CInode *in)
 {
@@ -595,6 +605,13 @@ void Locker::request_inode_file_caps(CInode *in)
     }
     assert(!in->is_auth());
 
+    // wait for single auth
+    if (in->is_ambiguous_auth()) {
+      in->add_waiter(MDSCacheObject::WAIT_SINGLEAUTH, 
+		     new C_MDL_RequestInodeFileCaps(this, in));
+      return;
+    }
+
     int auth = in->authority().first;
     dout(7) << "request_inode_file_caps " << cap_string(wanted)
             << " was " << cap_string(in->replica_caps_wanted) 
@@ -708,7 +725,7 @@ void Locker::handle_client_file_caps(MClientFileCaps *m)
     MClientFileCaps *r = new MClientFileCaps(MClientFileCaps::OP_RELEASE,
 					     in->inode, 
                                              0, 0, 0);
-    mds->send_message_client(r, m->get_source_inst());
+    mds->send_message_client_maybe_open(r, m->get_source_inst());
   }
 
   // merge in atime?
diff --git a/trunk/ceph/mds/Locker.h b/trunk/ceph/mds/Locker.h
index b54b0b7b2c..1a90b1a033 100644
--- a/trunk/ceph/mds/Locker.h
+++ b/trunk/ceph/mds/Locker.h
@@ -176,6 +176,7 @@ protected:
   void request_inode_file_caps(CInode *in);
   void handle_inode_file_caps(class MInodeFileCaps *m);
 
+  friend class C_MDL_RequestInodeFileCaps;
 
 };
 
diff --git a/trunk/ceph/mds/MDBalancer.cc b/trunk/ceph/mds/MDBalancer.cc
index dfcb3f385b..a3bfe55262 100644
--- a/trunk/ceph/mds/MDBalancer.cc
+++ b/trunk/ceph/mds/MDBalancer.cc
@@ -808,7 +808,7 @@ void MDBalancer::hit_dir(utime_t now, CDir *dir, int type, int who, double amoun
   // hit me
   double v = dir->pop_me.get(type).hit(now, amount);
   
-  //if (dir->ino() == inodeno_t(10000000001))
+  //if (dir->ino() == inodeno_t(0x10000000000))
   //dout(0) << "hit_dir " << type << " pop " << v << " in " << *dir << dendl;
 
   // hit modify counter, if this was a modify
@@ -838,7 +838,7 @@ void MDBalancer::hit_dir(utime_t now, CDir *dir, int type, int who, double amoun
     float pop_sp = dir->pop_spread.get(now);
     dir_pop += pop_sp * 10;
 
-    //if (dir->ino() == inodeno_t(10000000001))
+    //if (dir->ino() == inodeno_t(0x10000000002))
     if (pop_sp > 0) {
       dout(20) << "hit_dir " << type << " pop " << dir_pop << " spread " << pop_sp 
 	      << " " << dir->pop_spread.last[0]
@@ -848,7 +848,7 @@ void MDBalancer::hit_dir(utime_t now, CDir *dir, int type, int who, double amoun
 	      << " in " << *dir << dendl;
     }
     
-    if (dir->is_auth()) {
+    if (dir->is_auth() && !dir->is_ambiguous_auth()) {
       if (!dir->is_rep() &&
 	  dir_pop >= g_conf.mds_bal_replicate_threshold) {
 	// replicate
diff --git a/trunk/ceph/mds/MDCache.cc b/trunk/ceph/mds/MDCache.cc
index 741dbe0434..91089aa3e0 100644
--- a/trunk/ceph/mds/MDCache.cc
+++ b/trunk/ceph/mds/MDCache.cc
@@ -1566,6 +1566,16 @@ void MDCache::disambiguate_imports()
   }
   assert(my_ambiguous_imports.empty());
 
+  // verify all my subtrees are unambiguous!
+  for (map<CDir*,set<CDir*> >::iterator p = subtrees.begin();
+       p != subtrees.end();
+       ++p) {
+    CDir *dir = p->first;
+    if (dir->is_ambiguous_dir_auth()) 
+      dout(0) << "disambiguate_imports uh oh, dir_auth is still ambiguous for " << *dir << dendl;
+    assert(!dir->is_ambiguous_dir_auth());
+  }
+
   show_subtrees();
 }
 
@@ -1895,7 +1905,9 @@ void MDCache::rejoin_walk(CDir *dir, MMDSCacheRejoin *rejoin)
  */
 void MDCache::handle_cache_rejoin(MMDSCacheRejoin *m)
 {
-  dout(7) << "handle_cache_rejoin " << *m << " from " << m->get_source() << dendl;
+  dout(7) << "handle_cache_rejoin " << *m << " from " << m->get_source() 
+	  << " (" << m->get_payload().length() << " bytes)"
+	  << dendl;
 
   switch (m->op) {
   case MMDSCacheRejoin::OP_WEAK:
@@ -2383,7 +2395,7 @@ void MDCache::handle_cache_rejoin_ack(MMDSCacheRejoin *ack)
       }
       else if (!dn->is_null() &&
 	       q->second.is_null()) {
-	dout(10) << " had bad linkage for " << *dn << dendl;
+	dout(-10) << " had bad linkage for " << *dn << dendl;
 	assert(0);  // hrmpf.  unlink should use slave requests to clean this up during resolve.
       }
       dn->set_replica_nonce(q->second.nonce);
@@ -3173,6 +3185,11 @@ void MDCache::handle_cache_expire(MCacheExpire *m)
   
   dout(7) << "cache_expire from mds" << from << dendl;
 
+  if (mds->get_state() < MDSMap::STATE_REJOIN) {
+    delete m;
+    return;
+  }
+
   // loop over realms
   for (map<dirfrag_t,MCacheExpire::realm>::iterator p = m->realms.begin();
        p != m->realms.end();
diff --git a/trunk/ceph/mds/MDS.cc b/trunk/ceph/mds/MDS.cc
index c9ece0b419..0c120d8cc4 100644
--- a/trunk/ceph/mds/MDS.cc
+++ b/trunk/ceph/mds/MDS.cc
@@ -180,6 +180,7 @@ void MDS::reopen_logger(utime_t start)
     
     mds_logtype.add_set("buf");
     
+    mds_logtype.add_set("sm");
     mds_logtype.add_inc("ex");
     mds_logtype.add_inc("iex");
     mds_logtype.add_inc("im");
@@ -284,8 +285,17 @@ public:
   }
 };
 
+void MDS::send_message_client_maybe_opening(Message *m, int c)
+{
+  send_message_client_maybe_open(m, clientmap.get_inst(c));
+}
+
 void MDS::send_message_client_maybe_open(Message *m, entity_inst_t clientinst)
 {
+  // FIXME
+  //  _most_ ppl shoudl check for a client session, since migration may call this,
+  //  start opening, and then e.g. locker sends something else (through non-maybe_open 
+  //  version)
   int client = clientinst.name.num();
   if (!clientmap.have_session(client)) {
     // no session!
@@ -348,6 +358,7 @@ void MDS::tick()
     logger->set("l", (int)load.mds_load());
     logger->set("q", messenger->get_dispatch_queue_len());
     logger->set("buf", buffer_total_alloc);
+    logger->set("sm", mdcache->num_subtrees());
     
     mdcache->log_stat(logger);
   }
@@ -357,29 +368,7 @@ void MDS::tick()
     
     // balancer
     balancer->tick();
-    
-    // HACK to test hashing stuff
-    if (false) {
-      /*
-      static map<int,int> didhash;
-      if (elapsed.sec() > 15 && !didhash[whoami]) {
-	CInode *in = mdcache->get_inode(100000010);
-	if (in && in->dir) {
-	  if (in->dir->is_auth()) 
-	    mdcache->migrator->hash_dir(in->dir);
-	  didhash[whoami] = 1;
-	}
-      }
-      if (0 && elapsed.sec() > 25 && didhash[whoami] == 1) {
-	CInode *in = mdcache->get_inode(100000010);
-	if (in && in->dir) {
-	  if (in->dir->is_auth() && in->dir->is_hashed())
-	    mdcache->migrator->unhash_dir(in->dir);
-	  didhash[whoami] = 2;
-	}
-      }
-      */
-    }
+
   }
 }
 
@@ -1042,7 +1031,7 @@ void MDS::suicide()
     tick_event = 0;
   }
   timer.cancel_all();
-  timer.join();
+  //timer.join();  // this will deadlock from beacon_kill -> suicide
   
   // shut down cache
   mdcache->shutdown();
@@ -1150,6 +1139,13 @@ void MDS::my_dispatch(Message *m)
 
   
   // hack: thrash exports
+  static utime_t start;
+  utime_t now = g_clock.now();
+  if (start == utime_t()) 
+    start = now;
+  double el = now - start;
+  if (el > 30.0 &&
+	   el < 60.0)
   for (int i=0; i<g_conf.mds_thrash_exports; i++) {
     set<int> s;
     if (!is_active()) break;
@@ -1176,7 +1172,7 @@ void MDS::my_dispatch(Message *m)
       while (k--) p++;
       dest = *p;
     } while (dest == whoami);
-    mdcache->migrator->export_dir(dir,dest);
+    mdcache->migrator->export_dir_nicely(dir,dest);
   }
   // hack: thrash exports
   for (int i=0; i<g_conf.mds_thrash_fragments; i++) {
diff --git a/trunk/ceph/mds/MDS.h b/trunk/ceph/mds/MDS.h
index 28958305ba..7ce32f301b 100644
--- a/trunk/ceph/mds/MDS.h
+++ b/trunk/ceph/mds/MDS.h
@@ -222,6 +222,7 @@ class MDS : public Dispatcher {
 
   void send_message_client(Message *m, int client);
   void send_message_client(Message *m, entity_inst_t clientinst);
+  void send_message_client_maybe_opening(Message *m, int);
   void send_message_client_maybe_open(Message *m, entity_inst_t clientinst);
 
 
diff --git a/trunk/ceph/mds/Migrator.cc b/trunk/ceph/mds/Migrator.cc
index bdffb5585d..a7a219d7dd 100644
--- a/trunk/ceph/mds/Migrator.cc
+++ b/trunk/ceph/mds/Migrator.cc
@@ -618,9 +618,11 @@ void Migrator::export_frozen(CDir *dir)
 {
   dout(7) << "export_frozen on " << *dir << dendl;
   assert(dir->is_frozen());
-  int dest = export_peer[dir];
+  assert(dir->get_cum_auth_pins() == 0);
 
   // ok!
+  int dest = export_peer[dir];
+
   cache->show_subtrees();
 
   // note the bounds.
@@ -844,7 +846,7 @@ void Migrator::encode_export_inode(CInode *in, bufferlist& enc_state, int new_au
                                              it->second.wanted());
     entity_inst_t inst = mds->clientmap.get_inst(it->first);
     exported_client_map[it->first] = inst; 
-    mds->send_message_client(m, inst);
+    mds->send_message_client_maybe_open(m, inst);
   }
 
   // relax locks?
@@ -1883,6 +1885,7 @@ void Migrator::decode_import_inode(CDentry *dn, bufferlist& bl, int& off, int ol
   for (set<int>::iterator it = merged_client_caps.begin();
        it != merged_client_caps.end();
        it++) {
+    dout(0) << "merged caps for client" << *it << " on " << *in << dendl;
     MClientFileCaps *caps = new MClientFileCaps(MClientFileCaps::OP_REAP,
 						in->inode,
                                                 in->client_caps[*it].get_last_seq(),
diff --git a/trunk/ceph/mds/Server.cc b/trunk/ceph/mds/Server.cc
index 33976474b5..f29564043c 100644
--- a/trunk/ceph/mds/Server.cc
+++ b/trunk/ceph/mds/Server.cc
@@ -243,6 +243,7 @@ void Server::reconnect_clients()
   // init gather list
   reconnect_start = g_clock.now();
   client_reconnect_gather = mds->clientmap.get_session_set();
+  dout(1) << "reconnect_clients -- " << client_reconnect_gather.size() << " sessions" << dendl;
 }
 
 void Server::handle_client_reconnect(MClientReconnect *m)
@@ -350,9 +351,12 @@ void Server::process_reconnected_caps()
 void Server::client_reconnect_failure(int from) 
 {
   dout(5) << "client_reconnect_failure on client" << from << dendl;
-  client_reconnect_gather.erase(from);
-  if (client_reconnect_gather.empty()) 
-    reconnect_gather_finish();
+  if (mds->is_reconnect() &&
+      client_reconnect_gather.count(from)) {
+    client_reconnect_gather.erase(from);
+    if (client_reconnect_gather.empty()) 
+      reconnect_gather_finish();
+  }
 }
 
 void Server::reconnect_gather_finish()
diff --git a/trunk/ceph/mds/journal.cc b/trunk/ceph/mds/journal.cc
index ed3e6e8671..062262610e 100644
--- a/trunk/ceph/mds/journal.cc
+++ b/trunk/ceph/mds/journal.cc
@@ -423,6 +423,15 @@ void EMetaBlob::replay(MDS *mds)
 	in->dirfragtree = p->dirfragtree;
 	if (in->inode.is_symlink()) in->symlink = p->symlink;
 	mds->mdcache->add_inode(in);
+	if (!dn->is_null()) {
+	  if (dn->is_primary())
+	    dout(-10) << "EMetaBlob.replay FIXME had dentry linked to wrong inode " << *dn 
+		     << " " << *dn->get_inode()
+		     << " should be " << p->inode.ino
+		     << dendl;
+	  dir->unlink_inode(dn);
+	  //assert(0); // hrm!  fallout from sloppy unlink?  or?  hmmm FIXME investigate further
+	}
 	dir->link_primary_inode(dn, in);
 	if (p->dirty) in->_mark_dirty();
 	dout(10) << "EMetaBlob.replay added " << *in << dendl;

