commit 86d9f48534e800e4d62cdc1b5aaf539f4c1d47d6
Author: Joonsoo Kim <iamjoonsoo.kim@lge.com>
Date:   Thu Oct 27 17:46:18 2016 -0700

    mm/slab: fix kmemcg cache creation delayed issue
    
    There is a bug report that SLAB makes extreme load average due to over
    2000 kworker thread.
    
      https://bugzilla.kernel.org/show_bug.cgi?id=172981
    
    This issue is caused by kmemcg feature that try to create new set of
    kmem_caches for each memcg.  Recently, kmem_cache creation is slowed by
    synchronize_sched() and futher kmem_cache creation is also delayed since
    kmem_cache creation is synchronized by a global slab_mutex lock.  So,
    the number of kworker that try to create kmem_cache increases quietly.
    
    synchronize_sched() is for lockless access to node's shared array but
    it's not needed when a new kmem_cache is created.  So, this patch rules
    out that case.
    
    Fixes: 801faf0db894 ("mm/slab: lockless decision to grow cache")
    Link: http://lkml.kernel.org/r/1475734855-4837-1-git-send-email-iamjoonsoo.kim@lge.com
    Reported-by: Doug Smythies <dsmythies@telus.net>
    Tested-by: Doug Smythies <dsmythies@telus.net>
    Signed-off-by: Joonsoo Kim <iamjoonsoo.kim@lge.com>
    Cc: Christoph Lameter <cl@linux.com>
    Cc: Pekka Enberg <penberg@kernel.org>
    Cc: David Rientjes <rientjes@google.com>
    Cc: <stable@vger.kernel.org>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/mm/slab.c b/mm/slab.c
index 090fb26b3a39..c451e3f6bbf6 100644
--- a/mm/slab.c
+++ b/mm/slab.c
@@ -966,7 +966,7 @@ static int setup_kmem_cache_node(struct kmem_cache *cachep,
 	 * guaranteed to be valid until irq is re-enabled, because it will be
 	 * freed after synchronize_sched().
 	 */
-	if (force_change)
+	if (old_shared && force_change)
 		synchronize_sched();
 
 fail:

