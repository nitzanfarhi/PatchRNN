commit 6823ebbca1cbf8703eca3fbbe6fa7834feb0a24b
Author: Mark Probst <mark.probst@gmail.com>
Date:   Fri Mar 4 00:35:59 2011 +0100

    [sgen] Parallel nursery collection.
    
    Do parallel nursery collections when using the parallel
    Mark&Sweep collector.

diff --git a/mono/metadata/sgen-cardtable.c b/mono/metadata/sgen-cardtable.c
index ae9c2038804..b4e53c03b54 100644
--- a/mono/metadata/sgen-cardtable.c
+++ b/mono/metadata/sgen-cardtable.c
@@ -454,7 +454,7 @@ LOOP_HEAD:
 						major_collector.copy_object ((void**)elem, queue);
 						new = *(gpointer*)elem;
 						if (G_UNLIKELY (ptr_in_nursery (new)))
-							mono_sgen_add_to_global_remset (elem);
+							mono_sgen_add_to_global_remset (queue->allocator, elem);
 					}
 				}
 			}
diff --git a/mono/metadata/sgen-gc.c b/mono/metadata/sgen-gc.c
index 0efec81fc88..d82cc774062 100644
--- a/mono/metadata/sgen-gc.c
+++ b/mono/metadata/sgen-gc.c
@@ -440,6 +440,7 @@ static gpointer global_remset_cache [2];
  */
 #define DEFAULT_REMSET_SIZE 1024
 static RememberedSet* alloc_remset (int size, gpointer id);
+static RememberedSet* alloc_global_remset (SgenInternalAllocator *alc, int size, gpointer id);
 
 #define object_is_forwarded	SGEN_OBJECT_IS_FORWARDED
 #define object_is_pinned	SGEN_OBJECT_IS_PINNED
@@ -821,6 +822,7 @@ typedef char* (*ScanObjectFunc) (char*, GrayQueue*);
 static int stop_world (int generation);
 static int restart_world (int generation);
 static void scan_thread_data (void *start_nursery, void *end_nursery, gboolean precise, GrayQueue *queue);
+static void scan_from_global_remsets (void *start_nursery, void *end_nursery, GrayQueue *queue);
 static void scan_from_remsets (void *start_nursery, void *end_nursery, GrayQueue *queue);
 static void scan_from_registered_roots (CopyOrMarkObjectFunc copy_func, char *addr_start, char *addr_end, int root_type, GrayQueue *queue);
 static void scan_finalizer_entries (CopyOrMarkObjectFunc copy_func, FinalizeEntry *list, GrayQueue *queue);
@@ -1644,10 +1646,10 @@ global_remset_location_was_not_added (gpointer ptr)
  * lock must be held.  For serial collectors that is not necessary.
  */
 void
-mono_sgen_add_to_global_remset (gpointer ptr)
+mono_sgen_add_to_global_remset (SgenInternalAllocator *alc, gpointer ptr)
 {
 	RememberedSet *rs;
-	gboolean lock;
+	gboolean lock = major_collector.is_parallel;
 
 	if (use_cardtable) {
 		sgen_card_table_mark_address ((mword)ptr);
@@ -1656,7 +1658,6 @@ mono_sgen_add_to_global_remset (gpointer ptr)
 
 	g_assert (!ptr_in_nursery (ptr) && ptr_in_nursery (*(gpointer*)ptr));
 
-	lock = (current_collection_generation == GENERATION_OLD && major_collector.is_parallel);
 	if (lock)
 		LOCK_GLOBAL_REMSET;
 
@@ -1676,7 +1677,7 @@ mono_sgen_add_to_global_remset (gpointer ptr)
 		*(global_remset->store_next++) = (mword)ptr;
 		goto done;
 	}
-	rs = alloc_remset (global_remset->end_set - global_remset->data, NULL);
+	rs = alloc_global_remset (alc, global_remset->end_set - global_remset->data, NULL);
 	rs->next = global_remset;
 	global_remset = rs;
 	*(global_remset->store_next++) = (mword)ptr;
@@ -3053,6 +3054,7 @@ collect_nursery (size_t requested_size)
 	try_calculate_minor_collection_allowance (FALSE);
 
 	gray_object_queue_init (&gray_queue, mono_sgen_get_unmanaged_allocator ());
+	workers_init_distribute_gray_queue ();
 
 	num_minor_gcs++;
 	mono_stats.minor_gc_count ++;
@@ -3062,10 +3064,10 @@ collect_nursery (size_t requested_size)
 	/* pin from pinned handles */
 	init_pinning ();
 	mono_profiler_gc_event (MONO_GC_EVENT_MARK_START, 0);
-	pin_from_roots (nursery_start, nursery_next, &gray_queue);
+	pin_from_roots (nursery_start, nursery_next, WORKERS_DISTRIBUTE_GRAY_QUEUE);
 	/* identify pinned objects */
 	optimize_pin_queue (0);
-	next_pin_slot = pin_objects_from_addresses (nursery_section, pin_queue, pin_queue + next_pin_slot, nursery_start, nursery_next, &gray_queue);
+	next_pin_slot = pin_objects_from_addresses (nursery_section, pin_queue, pin_queue + next_pin_slot, nursery_start, nursery_next, WORKERS_DISTRIBUTE_GRAY_QUEUE);
 	nursery_section->pin_queue_start = pin_queue;
 	nursery_section->pin_queue_num_entries = next_pin_slot;
 	TV_GETTIME (atv);
@@ -3076,12 +3078,20 @@ collect_nursery (size_t requested_size)
 	if (consistency_check_at_minor_collection)
 		check_consistency ();
 
-	/* 
-	 * walk all the roots and copy the young objects to the old generation,
-	 * starting from to_space
+	workers_start_all_workers ();
+
+	/*
+	 * Walk all the roots and copy the young objects to the old
+	 * generation, starting from to_space.
+	 *
+	 * The global remsets must be processed before the workers start
+	 * marking because they might add global remsets.
 	 */
+	scan_from_global_remsets (nursery_start, nursery_next, WORKERS_DISTRIBUTE_GRAY_QUEUE);
+
+	workers_start_marking ();
 
-	scan_from_remsets (nursery_start, nursery_next, &gray_queue);
+	scan_from_remsets (nursery_start, nursery_next, WORKERS_DISTRIBUTE_GRAY_QUEUE);
 	/* we don't have complete write barrier yet, so we scan all the old generation sections */
 	TV_GETTIME (btv);
 	time_minor_scan_remsets += TV_ELAPSED_MS (atv, btv);
@@ -3090,12 +3100,13 @@ collect_nursery (size_t requested_size)
 	if (use_cardtable) {
 		atv = btv;
 		card_tables_collect_stats (TRUE);
-		scan_from_card_tables (nursery_start, nursery_next, &gray_queue);
+		scan_from_card_tables (nursery_start, nursery_next, WORKERS_DISTRIBUTE_GRAY_QUEUE);
 		TV_GETTIME (btv);
 		time_minor_scan_card_table += TV_ELAPSED_MS (atv, btv);
 	}
 
-	drain_gray_stack (&gray_queue, -1);
+	if (!major_collector.is_parallel)
+		drain_gray_stack (&gray_queue, -1);
 
 	if (mono_profiler_get_events () & MONO_PROFILE_GC_ROOTS)
 		report_registered_roots ();
@@ -3104,21 +3115,41 @@ collect_nursery (size_t requested_size)
 	TV_GETTIME (atv);
 	time_minor_scan_pinned += TV_ELAPSED_MS (btv, atv);
 	/* registered roots, this includes static fields */
-	scan_from_registered_roots (major_collector.copy_object, nursery_start, nursery_next, ROOT_TYPE_NORMAL, &gray_queue);
-	scan_from_registered_roots (major_collector.copy_object, nursery_start, nursery_next, ROOT_TYPE_WBARRIER, &gray_queue);
+	scan_from_registered_roots (major_collector.copy_object, nursery_start, nursery_next, ROOT_TYPE_NORMAL, WORKERS_DISTRIBUTE_GRAY_QUEUE);
+	scan_from_registered_roots (major_collector.copy_object, nursery_start, nursery_next, ROOT_TYPE_WBARRIER, WORKERS_DISTRIBUTE_GRAY_QUEUE);
 	TV_GETTIME (btv);
 	time_minor_scan_registered_roots += TV_ELAPSED_MS (atv, btv);
 	/* thread data */
-	scan_thread_data (nursery_start, nursery_next, TRUE, &gray_queue);
+	scan_thread_data (nursery_start, nursery_next, TRUE, WORKERS_DISTRIBUTE_GRAY_QUEUE);
 	TV_GETTIME (atv);
 	time_minor_scan_thread_data += TV_ELAPSED_MS (btv, atv);
 	btv = atv;
 
+	if (major_collector.is_parallel) {
+		while (!gray_object_queue_is_empty (WORKERS_DISTRIBUTE_GRAY_QUEUE)) {
+			workers_distribute_gray_queue_sections ();
+			usleep (1000);
+		}
+	}
+	workers_join ();
+
+	if (major_collector.is_parallel)
+		g_assert (gray_object_queue_is_empty (&gray_queue));
+
 	finish_gray_stack (nursery_start, nursery_next, GENERATION_NURSERY, &gray_queue);
 	TV_GETTIME (atv);
 	time_minor_finish_gray_stack += TV_ELAPSED_MS (btv, atv);
 	mono_profiler_gc_event (MONO_GC_EVENT_MARK_END, 0);
 
+	/*
+	 * The (single-threaded) finalization code might have done
+	 * some copying/marking so we can only reset the GC thread's
+	 * worker data here instead of earlier when we joined the
+	 * workers.
+	 */
+	if (major_collector.reset_worker_data)
+		major_collector.reset_worker_data (workers_gc_thread_data.major_collector_data);
+
 	if (objects_pinned) {
 		evacuate_pin_staging_area ();
 		optimize_pin_queue (0);
@@ -4391,11 +4422,11 @@ clear_unreachable_ephemerons (CopyOrMarkObjectFunc copy_func, char *start, char
 			if (was_promoted) {
 				if (ptr_in_nursery (key)) {/*key was not promoted*/
 					DEBUG (5, fprintf (gc_debug_file, "\tAdded remset to key %p\n", key));
-					mono_sgen_add_to_global_remset (&cur->key);
+					mono_sgen_add_to_global_remset (queue->allocator, &cur->key);
 				}
 				if (ptr_in_nursery (cur->value)) {/*value was not promoted*/
 					DEBUG (5, fprintf (gc_debug_file, "\tAdded remset to value %p\n", cur->value));
-					mono_sgen_add_to_global_remset (&cur->value);
+					mono_sgen_add_to_global_remset (queue->allocator, &cur->value);
 				}
 			}
 		}
@@ -5521,7 +5552,7 @@ handle_remset (mword *p, void *start_nursery, void *end_nursery, gboolean global
 				 * becomes part of the global remset, which can grow very large.
 				 */
 				DEBUG (9, fprintf (gc_debug_file, "Add to global remset because of pinning %p (%p %s)\n", ptr, *ptr, safe_name (*ptr)));
-				mono_sgen_add_to_global_remset (ptr);
+				mono_sgen_add_to_global_remset (queue->allocator, ptr);
 			}
 		} else {
 			DEBUG (9, fprintf (gc_debug_file, "Skipping remset at %p holding %p\n", ptr, *ptr));
@@ -5536,7 +5567,7 @@ handle_remset (mword *p, void *start_nursery, void *end_nursery, gboolean global
 			major_collector.copy_object (ptr, queue);
 			DEBUG (9, fprintf (gc_debug_file, "Overwrote remset at %p with %p (count: %d)\n", ptr, *ptr, (int)count));
 			if (!global && *ptr >= start_nursery && *ptr < end_nursery)
-				mono_sgen_add_to_global_remset (ptr);
+				mono_sgen_add_to_global_remset (queue->allocator, ptr);
 			++ptr;
 		}
 		return p + 2;
@@ -5665,18 +5696,11 @@ remset_byte_size (RememberedSet *remset)
 }
 
 static void
-scan_from_remsets (void *start_nursery, void *end_nursery, GrayQueue *queue)
+scan_from_global_remsets (void *start_nursery, void *end_nursery, GrayQueue *queue)
 {
-	int i;
-	SgenThreadInfo *info;
 	RememberedSet *remset;
-	GenericStoreRememberedSet *store_remset;
 	mword *p, *next_p, *store_pos;
 
-#ifdef HEAVY_STATISTICS
-	remset_stats ();
-#endif
-
 	/* the global one */
 	for (remset = global_remset; remset; remset = remset->next) {
 		DEBUG (4, fprintf (gc_debug_file, "Scanning global remset range: %p-%p, size: %td\n", remset->data, remset->store_next, remset->store_next - remset->data));
@@ -5708,6 +5732,20 @@ scan_from_remsets (void *start_nursery, void *end_nursery, GrayQueue *queue)
 		/* Truncate the remset */
 		remset->store_next = store_pos;
 	}
+}
+
+static void
+scan_from_remsets (void *start_nursery, void *end_nursery, GrayQueue *queue)
+{
+	int i;
+	SgenThreadInfo *info;
+	RememberedSet *remset;
+	GenericStoreRememberedSet *store_remset;
+	mword *p;
+
+#ifdef HEAVY_STATISTICS
+	remset_stats ();
+#endif
 
 	/* the generic store ones */
 	store_remset = generic_store_remsets;
@@ -5779,7 +5817,8 @@ clear_remsets (void)
 		remset->next = NULL;
 		if (remset != global_remset) {
 			DEBUG (4, fprintf (gc_debug_file, "Freed remset at %p\n", remset->data));
-			mono_sgen_free_internal_dynamic (remset, remset_byte_size (remset), INTERNAL_MEM_REMSET);
+			mono_sgen_free_internal_dynamic_delayed (remset, remset_byte_size (remset), INTERNAL_MEM_REMSET,
+					mono_sgen_get_unmanaged_allocator ());
 		}
 	}
 	/* the generic store ones */
@@ -6144,6 +6183,17 @@ alloc_remset (int size, gpointer id) {
 	return res;
 }
 
+static RememberedSet*
+alloc_global_remset (SgenInternalAllocator *alc, int size, gpointer id)
+{
+	RememberedSet* res = mono_sgen_alloc_internal_full (alc, sizeof (RememberedSet) + (size * sizeof (gpointer)), INTERNAL_MEM_REMSET);
+	res->store_next = res->data;
+	res->end_set = res->data + size;
+	res->next = NULL;
+	DEBUG (4, fprintf (gc_debug_file, "Allocated global remset size %d at %p for %p\n", size, res->data, id));
+	return res;
+}
+
 /*
  * Note: the write barriers first do the needed GC work and then do the actual store:
  * this way the value is visible to the conservative GC scan after the write barrier
diff --git a/mono/metadata/sgen-gc.h b/mono/metadata/sgen-gc.h
index 08c7f7338c3..4ce9050d576 100644
--- a/mono/metadata/sgen-gc.h
+++ b/mono/metadata/sgen-gc.h
@@ -682,6 +682,8 @@ void* mono_sgen_alloc_internal_full (SgenInternalAllocator *allocator, size_t si
 void mono_sgen_free_internal_full (SgenInternalAllocator *allocator, void *addr, size_t size, int type) MONO_INTERNAL;
 
 void mono_sgen_free_internal_delayed (void *addr, int type, SgenInternalAllocator *thread_allocator) MONO_INTERNAL;
+void mono_sgen_free_internal_dynamic_delayed (void *addr, size_t size, int type, SgenInternalAllocator *thread_allocator) MONO_INTERNAL;
+
 
 void mono_sgen_debug_printf (int level, const char *format, ...) MONO_INTERNAL;
 
@@ -698,7 +700,7 @@ void mono_sgen_pin_objects_in_section (GCMemSection *section, SgenGrayQueue *que
 
 void mono_sgen_pin_stats_register_object (char *obj, size_t size);
 
-void mono_sgen_add_to_global_remset (gpointer ptr) MONO_INTERNAL;
+void mono_sgen_add_to_global_remset (SgenInternalAllocator *alc, gpointer ptr) MONO_INTERNAL;
 
 int mono_sgen_get_current_collection_generation (void) MONO_INTERNAL;
 
diff --git a/mono/metadata/sgen-internal.c b/mono/metadata/sgen-internal.c
index 0620537feef..9b78b118604 100644
--- a/mono/metadata/sgen-internal.c
+++ b/mono/metadata/sgen-internal.c
@@ -485,28 +485,44 @@ mono_sgen_free_internal_dynamic (void *addr, size_t size, int type)
 	mono_sgen_free_internal_full (&unmanaged_allocator, addr, size, type);
 }
 
-void
-mono_sgen_free_internal_delayed (void *addr, int type, SgenInternalAllocator *thread_allocator)
+static void
+free_from_slot_delayed (void *addr, size_t size, int slot, int type, SgenInternalAllocator *thread_allocator)
 {
 	SgenPinnedChunk *pchunk = (SgenPinnedChunk*)SGEN_PINNED_CHUNK_FOR_PTR (addr);
 	SgenInternalAllocator *alc = pchunk->allocator;
-	int slot;
 	void *next;
 
 	if (alc == thread_allocator) {
-		mono_sgen_free_internal_fixed (alc, addr, type);
+		if (size > 0)
+			mono_sgen_free_internal_full (alc, addr, size, type);
+		else
+			mono_sgen_free_internal_fixed (alc, addr, type);
 		return;
 	}
 
-	slot = fixed_type_freelist_slots [type];
-	g_assert (slot >= 0);
-
 	do {
 		next = alc->delayed_free_lists [slot];
 		*(void**)addr = next;
 	} while (SGEN_CAS_PTR (&alc->delayed_free_lists [slot], addr, next) != next);
 }
 
+void
+mono_sgen_free_internal_delayed (void *addr, int type, SgenInternalAllocator *thread_allocator)
+{
+	free_from_slot_delayed (addr, 0, fixed_type_freelist_slots [type], type, thread_allocator);
+}
+
+void
+mono_sgen_free_internal_dynamic_delayed (void *addr, size_t size, int type, SgenInternalAllocator *thread_allocator)
+{
+	if (size > freelist_sizes [SGEN_INTERNAL_FREELIST_NUM_SLOTS - 1]) {
+		mono_sgen_free_internal_full (NULL, addr, size, type);
+		return;
+	}
+
+	free_from_slot_delayed (addr, size, slot_for_size (size), type, thread_allocator);
+}
+
 void
 mono_sgen_dump_internal_mem_usage (FILE *heap_dump_file)
 {
diff --git a/mono/metadata/sgen-major-copy-object.h b/mono/metadata/sgen-major-copy-object.h
index a8a61951c57..c6d31585c15 100644
--- a/mono/metadata/sgen-major-copy-object.h
+++ b/mono/metadata/sgen-major-copy-object.h
@@ -82,6 +82,77 @@ par_copy_object_no_checks (char *destination, MonoVTable *vt, void *obj, mword o
 	}
 }
 
+#ifdef SGEN_PARALLEL_MARK
+static void
+copy_object (void **obj_slot, SgenGrayQueue *queue)
+{
+	char *obj = *obj_slot;
+	mword vtable_word, objsize;
+	MonoVTable *vt;
+	void *destination;
+	gboolean has_references;
+
+	DEBUG (9, g_assert (current_collection_generation == GENERATION_NURSERY));
+
+	HEAVY_STAT (++stat_copy_object_called_nursery);
+
+	if (!ptr_in_nursery (obj)) {
+		HEAVY_STAT (++stat_nursery_copy_object_failed_from_space);
+		return;
+	}
+
+	vtable_word = *(mword*)obj;
+	vt = (MonoVTable*)(vtable_word & ~SGEN_VTABLE_BITS_MASK);
+
+	/*
+	 * Before we can copy the object we must make sure that we are
+	 * allowed to, i.e. that the object not pinned or not already
+	 * forwarded.
+	 */
+
+	if (vtable_word & SGEN_FORWARDED_BIT) {
+		HEAVY_STAT (++stat_nursery_copy_object_failed_forwarded);
+		*obj_slot = vt;
+		return;
+	}
+	if (vtable_word & SGEN_PINNED_BIT) {
+		HEAVY_STAT (++stat_nursery_copy_object_failed_pinned);
+		return;
+	}
+
+	HEAVY_STAT (++stat_objects_copied_nursery);
+
+	objsize = SGEN_ALIGN_UP (mono_sgen_par_object_get_size (vt, (MonoObject*)obj));
+	has_references = SGEN_VTABLE_HAS_REFERENCES (vt);
+
+	destination = alloc_obj_par (objsize, FALSE, has_references);
+
+	if (G_UNLIKELY (!destination)) {
+		pin_or_update_par (obj_slot, obj, vt, queue);
+		return;
+	}
+
+	if (SGEN_CAS_PTR ((void*)obj, (void*)((mword)destination | SGEN_FORWARDED_BIT), vt) == vt) {
+		par_copy_object_no_checks (destination, vt, obj, objsize, has_references ? queue : NULL);
+		obj = destination;
+		*obj_slot = obj;
+	} else {
+		/* FIXME: unify with code in major_copy_or_mark_object() */
+
+		/* FIXME: Give destination back to the allocator. */
+		*(void**)destination = NULL;
+
+		vtable_word = *(mword*)obj;
+		g_assert (vtable_word & SGEN_FORWARDED_BIT);
+
+		obj = (void*)(vtable_word & ~SGEN_VTABLE_BITS_MASK);
+
+		*obj_slot = obj;
+
+		++stat_slots_allocated_in_vain;
+	}
+}
+#else
 static void*
 copy_object_no_checks (void *obj, SgenGrayQueue *queue)
 {
@@ -164,6 +235,7 @@ copy_object (void **obj_slot, SgenGrayQueue *queue)
 
 	*obj_slot = copy_object_no_checks (obj, queue);
 }
+#endif
 
 #define FILL_COLLECTOR_COPY_OBJECT(collector)	do {			\
 		(collector)->copy_object = copy_object;			\
diff --git a/mono/metadata/sgen-major-scan-object.h b/mono/metadata/sgen-major-scan-object.h
index bcd37489ad1..a09b38e0ba4 100644
--- a/mono/metadata/sgen-major-scan-object.h
+++ b/mono/metadata/sgen-major-scan-object.h
@@ -33,7 +33,7 @@ extern long long stat_scan_object_called_major;
 			__copy = *(ptr);	\
 			DEBUG (9, if (__old != __copy) fprintf (gc_debug_file, "Overwrote field at %p with %p (was: %p)\n", (ptr), *(ptr), __old));	\
 			if (G_UNLIKELY (ptr_in_nursery (__copy) && !ptr_in_nursery ((ptr)))) \
-				mono_sgen_add_to_global_remset ((ptr));	\
+				mono_sgen_add_to_global_remset (queue->allocator, (ptr));	\
 		}	\
 	} while (0)
 
@@ -104,7 +104,7 @@ minor_scan_vtype (char *start, mword desc, char* from_start, char* from_end, Sge
 			__copy = *(ptr);				\
 			DEBUG (9, if (__old != __copy) mono_sgen_debug_printf (9, "Overwrote field at %p with %p (was: %p)\n", (ptr), *(ptr), __old)); \
 			if (G_UNLIKELY (ptr_in_nursery (__copy) && !ptr_in_nursery ((ptr)))) \
-				mono_sgen_add_to_global_remset ((ptr));	\
+				mono_sgen_add_to_global_remset (queue->allocator, (ptr));	\
 		}							\
 	} while (0)
 
diff --git a/mono/metadata/sgen-marksweep.c b/mono/metadata/sgen-marksweep.c
index 3fcf6a592ec..dc0c188f3d5 100644
--- a/mono/metadata/sgen-marksweep.c
+++ b/mono/metadata/sgen-marksweep.c
@@ -1009,6 +1009,32 @@ major_dump_heap (FILE *heap_dump_file)
 		}							\
 	} while (0)
 
+#ifdef SGEN_PARALLEL_MARK
+static void
+pin_or_update_par (void **ptr, void *obj, MonoVTable *vt, SgenGrayQueue *queue)
+{
+	for (;;) {
+		mword vtable_word;
+
+		if (SGEN_CAS_PTR (obj, (void*)((mword)vt | SGEN_PINNED_BIT), vt) == vt) {
+			mono_sgen_pin_object (obj, queue);
+			break;
+		}
+
+		vtable_word = *(mword*)obj;
+		/*someone else forwarded it, update the pointer and bail out*/
+		if (vtable_word & SGEN_FORWARDED_BIT) {
+			*ptr = (void*)(vtable_word & ~SGEN_VTABLE_BITS_MASK);
+			break;
+		}
+
+		/*someone pinned it, nothing to do.*/
+		if (vtable_word & SGEN_PINNED_BIT)
+			break;
+	}
+}
+#endif
+
 #include "sgen-major-copy-object.h"
 
 #ifdef SGEN_PARALLEL_MARK
@@ -1055,23 +1081,7 @@ major_copy_or_mark_object (void **ptr, SgenGrayQueue *queue)
 				evacuate_block_obj_sizes [size_index] = FALSE;
 			}
 
-			do {
-				if (SGEN_CAS_PTR (obj, (void*)((mword)vt | SGEN_PINNED_BIT), vt) == vt) {
-					mono_sgen_pin_object (obj, queue);
-					break;
-				}
-
-				vtable_word = *(mword*)obj;
-				/*someone else forwarded it, update the pointer and bail out*/
-				if (vtable_word & SGEN_FORWARDED_BIT) {
-					*ptr = (void*)(vtable_word & ~SGEN_VTABLE_BITS_MASK);
-					break;
-				}
-
-				/*someone pinned it, nothing to do.*/
-				if (vtable_word & SGEN_PINNED_BIT)
-					break;
-			} while (TRUE);
+			pin_or_update_par (ptr, obj, vt, queue);
 			return;
 		}
 
diff --git a/mono/metadata/sgen-workers.c b/mono/metadata/sgen-workers.c
index aab3988ed98..d16a90afed8 100644
--- a/mono/metadata/sgen-workers.c
+++ b/mono/metadata/sgen-workers.c
@@ -342,8 +342,12 @@ workers_distribute_gray_queue_sections (void)
 static void
 workers_init_distribute_gray_queue (void)
 {
-	if (!major_collector.is_parallel)
+	if (!major_collector.is_parallel) {
+#ifdef SGEN_DEBUG_INTERNAL_ALLOC
+		mono_sgen_get_unmanaged_allocator ()->thread = pthread_self ();
+#endif
 		return;
+	}
 
 	gray_object_queue_init (&workers_distribute_gray_queue, &workers_distribute_gray_queue_allocator);
 #ifdef SGEN_DEBUG_INTERNAL_ALLOC
@@ -454,8 +458,12 @@ workers_join (void)
 {
 	int i;
 
-	if (!major_collector.is_parallel)
+	if (!major_collector.is_parallel) {
+#ifdef SGEN_DEBUG_INTERNAL_ALLOC
+		mono_sgen_get_unmanaged_allocator ()->thread = NULL;
+#endif
 		return;
+	}
 
 	g_assert (gray_object_queue_is_empty (&workers_gc_thread_data.private_gray_queue));
 	g_assert (gray_object_queue_is_empty (&workers_distribute_gray_queue));

