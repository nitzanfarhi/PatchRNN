commit a5998fcb92552a18713b6aa5c146aa400e4d75ee
Author: Aneesh Kumar K.V <aneesh.kumar@linux.vnet.ibm.com>
Date:   Wed Apr 26 21:38:17 2017 +1000

    powerpc/mm/radix: Optimise tlbiel flush all case
    
    _tlbiel_pid() is called with a ric (Radix Invalidation Control) argument of
    either RIC_FLUSH_TLB or RIC_FLUSH_ALL.
    
    RIC_FLUSH_ALL says to invalidate the entire TLB and the Page Walk Cache (PWC).
    
    To flush the whole TLB, we have to iterate over each set (congruence class) of
    the TLB. Currently we do that and pass RIC_FLUSH_ALL each time. That is not
    incorrect but it means we flush the PWC 128 times, when once would suffice.
    
    Fix it by doing the first flush with the ric value we're passed, and then if it
    was RIC_FLUSH_ALL, we downgrade it to RIC_FLUSH_TLB, because we know we have
    just flushed the PWC and don't need to do it again.
    
    Signed-off-by: Aneesh Kumar K.V <aneesh.kumar@linux.vnet.ibm.com>
    [mpe: Split out of combined patch, tweak logic, rewrite change log]
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/mm/tlb-radix.c b/arch/powerpc/mm/tlb-radix.c
index ae2e799822bd..5e17c4e873a5 100644
--- a/arch/powerpc/mm/tlb-radix.c
+++ b/arch/powerpc/mm/tlb-radix.c
@@ -46,9 +46,20 @@ static inline void _tlbiel_pid(unsigned long pid, unsigned long ric)
 	int set;
 
 	asm volatile("ptesync": : :"memory");
-	for (set = 0; set < POWER9_TLB_SETS_RADIX ; set++) {
+
+	/*
+	 * Flush the first set of the TLB, and if we're doing a RIC_FLUSH_ALL,
+	 * also flush the entire Page Walk Cache.
+	 */
+	__tlbiel_pid(pid, 0, ric);
+
+	if (ric == RIC_FLUSH_ALL)
+		/* For the remaining sets, just flush the TLB */
+		ric = RIC_FLUSH_TLB;
+
+	for (set = 1; set < POWER9_TLB_SETS_RADIX ; set++)
 		__tlbiel_pid(pid, set, ric);
-	}
+
 	asm volatile("ptesync": : :"memory");
 	asm volatile(PPC_INVALIDATE_ERAT "; isync" : : :"memory");
 }

