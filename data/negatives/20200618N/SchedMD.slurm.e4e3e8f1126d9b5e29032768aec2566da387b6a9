commit e4e3e8f1126d9b5e29032768aec2566da387b6a9
Author: Moe Jette <jette1@llnl.gov>
Date:   Mon Jan 13 17:27:26 2003 +0000

    Minor code clean-up, no logic changes.

diff --git a/src/slurmctld/agent.c b/src/slurmctld/agent.c
index aa83fba322..7e0707ed85 100644
--- a/src/slurmctld/agent.c
+++ b/src/slurmctld/agent.c
@@ -253,15 +253,15 @@ void *agent(void *args)
 				_slurmctld_free_job_launch_msg
 				    (agent_arg_ptr->msg_args);
 			else
-				FREE_NULL(agent_arg_ptr->msg_args);
+				xfree(agent_arg_ptr->msg_args);
 		}
-		FREE_NULL(agent_arg_ptr);
+		xfree(agent_arg_ptr);
 	}
 #endif
 
 	if (agent_info_ptr) {
 		FREE_NULL(agent_info_ptr->thread_struct);
-		FREE_NULL(agent_info_ptr);
+		xfree(agent_info_ptr);
 	}
 	return NULL;
 }
@@ -374,7 +374,7 @@ static void *_wdog(void *args)
 		fatal
 		    ("Code development needed here if agent is not thread");
 
-		FREE_NULL(slurm_names);
+		xfree(slurm_names);
 #endif
 		if (agent_ptr->retry)
 			_queue_agent_retry(agent_ptr, fail_cnt);
@@ -404,7 +404,7 @@ static void *_wdog(void *args)
 	/* send RPC */
 	fatal("Code development needed here if agent is not thread");
 
-	FREE_NULL(slurm_addr);
+	xfree(slurm_addr);
 #endif
 	if (max_delay)
 		debug("agent maximum delay %d seconds", max_delay);
@@ -522,7 +522,7 @@ static void *_thread_per_node_rpc(void *args)
 	slurm_mutex_unlock(task_ptr->thread_mutex_ptr);
 
 	slurm_free_msg(response_msg);
-	FREE_NULL(args);
+	xfree(args);
 	return (void *) NULL;
 }
 
@@ -613,7 +613,7 @@ static void _list_delete_retry(void *retry_entry)
 #if AGENT_IS_THREAD
 	FREE_NULL(agent_arg_ptr->msg_args);
 #endif
-	FREE_NULL(agent_arg_ptr);
+	xfree(agent_arg_ptr);
 }
 
 
diff --git a/src/slurmctld/read_config.c b/src/slurmctld/read_config.c
index d9573f89fe..fcb86dbc37 100644
--- a/src/slurmctld/read_config.c
+++ b/src/slurmctld/read_config.c
@@ -318,7 +318,6 @@ static int _parse_node_spec(char *in_line)
 		}
 		if (strcasecmp(this_node_name, "DEFAULT") == 0) {
 			FREE_NULL(node_name);
-			node_name = NULL;
 			if (cpus_val != NO_VAL)
 				default_config_record.cpus = cpus_val;
 			if (real_memory_val != NO_VAL)
@@ -449,7 +448,7 @@ static int _parse_part_spec(char *in_line)
 	if (strlen(partition_name) >= MAX_NAME_LEN) {
 		error("_parse_part_spec: partition name %s too long",
 		      partition_name);
-		FREE_NULL(partition_name);
+		xfree(partition_name);
 		return EINVAL;
 	}
 
@@ -531,7 +530,7 @@ static int _parse_part_spec(char *in_line)
 	}
 
 	if (strcasecmp(partition_name, "DEFAULT") == 0) {
-		FREE_NULL(partition_name);
+		xfree(partition_name);
 		if (max_time_val != NO_VAL)
 			default_part.max_time = max_time_val;
 		if (max_nodes_val != NO_VAL)
@@ -590,7 +589,7 @@ static int _parse_part_spec(char *in_line)
 	if (nodes) {
 		FREE_NULL(part_record_point->nodes);
 		if (strcmp(nodes, "localhost") == 0) {
-			FREE_NULL(nodes);
+			xfree(nodes);
 			nodes = xmalloc(128);
 			if (nodes == NULL)
 				fatal("memory allocation failure");
@@ -599,7 +598,7 @@ static int _parse_part_spec(char *in_line)
 		part_record_point->nodes = nodes;
 		nodes = NULL;
 	}
-	FREE_NULL(partition_name);
+	xfree(partition_name);
 	return 0;
 
       cleanup:
@@ -748,7 +747,7 @@ int read_slurm_conf(int recover)
 				node_record_point->node_state =
 				    old_node_table_ptr[i].node_state;
 		}
-		FREE_NULL(old_node_table_ptr);
+		xfree(old_node_table_ptr);
 	}
 	set_slurmd_addr();
 

