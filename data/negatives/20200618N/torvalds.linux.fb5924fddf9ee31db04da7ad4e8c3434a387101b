commit fb5924fddf9ee31db04da7ad4e8c3434a387101b
Author: Balbir Singh <bsingharora@gmail.com>
Date:   Fri Apr 6 15:24:23 2018 +1000

    powerpc/mm: Flush cache on memory hot(un)plug
    
    This patch adds support for flushing potentially dirty cache lines
    when memory is hot-plugged/hot-un-plugged. The support is currently
    limited to 64 bit systems.
    
    The bug was exposed when mappings for a device were actually
    hot-unplugged and plugged in back later. A similar issue was observed
    during the development of memtrace, but memtrace does it's own
    flushing of region via a custom routine.
    
    These patches do a flush both on hotplug/unplug to clear any stale
    data in the cache w.r.t mappings, there is a small race window where a
    clean cache line may be created again just prior to tearing down the
    mapping.
    
    The patches were tested by disabling the flush routines in memtrace
    and doing I/O on the trace file. The system immediately
    checkstops (quite reliablly if prior to the hot-unplug of the memtrace
    region, we memset the regions we are about to hot unplug). After these
    patches no custom flushing is needed in the memtrace code.
    
    Fixes: 9d5171a8f248 ("powerpc/powernv: Enable removal of memory for in memory tracing")
    Cc: stable@vger.kernel.org # v4.14+
    Signed-off-by: Balbir Singh <bsingharora@gmail.com>
    Acked-by: Reza Arbab <arbab@linux.ibm.com>
    Reviewed-by: Rashmica Gupta <rashmica.g@gmail.com>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/mm/mem.c b/arch/powerpc/mm/mem.c
index 737f8a4632cc..c3c39b02b2ba 100644
--- a/arch/powerpc/mm/mem.c
+++ b/arch/powerpc/mm/mem.c
@@ -133,6 +133,7 @@ int __meminit arch_add_memory(int nid, u64 start, u64 size, struct vmem_altmap *
 			start, start + size, rc);
 		return -EFAULT;
 	}
+	flush_inval_dcache_range(start, start + size);
 
 	return __add_pages(nid, start_pfn, nr_pages, altmap, want_memblock);
 }
@@ -159,6 +160,7 @@ int __meminit arch_remove_memory(u64 start, u64 size, struct vmem_altmap *altmap
 
 	/* Remove htab bolted mappings for this section of memory */
 	start = (unsigned long)__va(start);
+	flush_inval_dcache_range(start, start + size);
 	ret = remove_section_mapping(start, start + size);
 
 	/* Ensure all vmalloc mappings are flushed in case they also

