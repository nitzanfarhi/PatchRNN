commit eeee9a8cd1e93c8b94e7788790fa9e2f8910c779
Author: KOSAKI Motohiro <kosaki.motohiro@jp.fujitsu.com>
Date:   Wed Jan 7 18:08:17 2009 -0800

    mm: make get_scan_ratio() safe for memcg
    
    Currently, get_scan_ratio() always calculate the balancing value for
    global reclaim and memcg reclaim doesn't use it.  Therefore it doesn't
    have scan_global_lru() condition.
    
    However, we plan to expand get_scan_ratio() to be usable for memcg too,
    latter.  Then, The dependency code of global reclaim in the
    get_scan_ratio() insert into scan_global_lru() condision explictly.
    
    This patch doesn't have any functional change.
    
    Acked-by: Rik van Riel <riel@redhat.com>
    Signed-off-by: KOSAKI Motohiro <kosaki.motohiro@jp.fujitsu.com>
    Cc: Balbir Singh <balbir@in.ibm.com>
    Cc: Daisuke Nishimura <nishimura@mxp.nes.nec.co.jp>
    Cc: Hugh Dickins <hugh@veritas.com>
    Cc: KOSAKI Motohiro <kosaki.motohiro@jp.fujitsu.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/mm/vmscan.c b/mm/vmscan.c
index 6827d35954fb..e2b31a522a66 100644
--- a/mm/vmscan.c
+++ b/mm/vmscan.c
@@ -1376,13 +1376,16 @@ static void get_scan_ratio(struct zone *zone, struct scan_control *sc,
 		zone_nr_pages(zone, sc, LRU_INACTIVE_ANON);
 	file  = zone_nr_pages(zone, sc, LRU_ACTIVE_FILE) +
 		zone_nr_pages(zone, sc, LRU_INACTIVE_FILE);
-	free  = zone_page_state(zone, NR_FREE_PAGES);
 
-	/* If we have very few page cache pages, force-scan anon pages. */
-	if (unlikely(file + free <= zone->pages_high)) {
-		percent[0] = 100;
-		percent[1] = 0;
-		return;
+	if (scan_global_lru(sc)) {
+		free  = zone_page_state(zone, NR_FREE_PAGES);
+		/* If we have very few page cache pages,
+		   force-scan anon pages. */
+		if (unlikely(file + free <= zone->pages_high)) {
+			percent[0] = 100;
+			percent[1] = 0;
+			return;
+		}
 	}
 
 	/*

