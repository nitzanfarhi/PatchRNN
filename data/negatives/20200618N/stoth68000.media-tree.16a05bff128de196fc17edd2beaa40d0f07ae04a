commit 16a05bff128de196fc17edd2beaa40d0f07ae04a
Author: Li Zhong <zhong@linux.vnet.ibm.com>
Date:   Wed Jun 11 16:23:39 2014 +0800

    powerpc: start loop at section start of start in vmemmap_populated()
    
    vmemmap_populated() checks whether the [start, start + page_size) has valid
    pfn numbers, to know whether a vmemmap mapping has been created that includes
    this range.
    
    Some range before end might not be checked by this loop:
      sec11start......start11..sec11end/sec12start..end....start12..sec12end
    as the above, for start11(section 11), it checks [sec11start, sec11end), and
    loop ends as the next start(start12) is bigger than end. However,
    [sec11end/sec12start, end) is not checked here.
    
    So before the loop, adjust the start to be the start of the section, so we don't miss ranges like the above.
    
    After we adjust start to be the start of the section, it also means it's
    aligned with vmemmap as of the sizeof struct page, so we could use
    page_to_pfn directly in the loop.
    
    Signed-off-by: Li Zhong <zhong@linux.vnet.ibm.com>
    Cc: Nathan Fontenot <nfont@linux.vnet.ibm.com>
    Acked-by: Nathan Fontenot <nfont@linux.vnet.ibm.com>
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/powerpc/mm/init_64.c b/arch/powerpc/mm/init_64.c
index 496379013873..253b4b971c8a 100644
--- a/arch/powerpc/mm/init_64.c
+++ b/arch/powerpc/mm/init_64.c
@@ -175,9 +175,10 @@ static unsigned long __meminit vmemmap_section_start(unsigned long page)
 static int __meminit vmemmap_populated(unsigned long start, int page_size)
 {
 	unsigned long end = start + page_size;
+	start = (unsigned long)(pfn_to_page(vmemmap_section_start(start)));
 
 	for (; start < end; start += (PAGES_PER_SECTION * sizeof(struct page)))
-		if (pfn_valid(vmemmap_section_start(start)))
+		if (pfn_valid(page_to_pfn((struct page *)start)))
 			return 1;
 
 	return 0;

