commit e3ae116339f9a0c77523abc95e338fa405946e07
Author: Mark Rutland <mark.rutland@arm.com>
Date:   Wed Mar 9 14:08:15 2016 -0800

    kasan: add functions to clear stack poison
    
    Functions which the compiler has instrumented for ASAN place poison on
    the stack shadow upon entry and remove this poison prior to returning.
    
    In some cases (e.g. hotplug and idle), CPUs may exit the kernel a
    number of levels deep in C code.  If there are any instrumented
    functions on this critical path, these will leave portions of the idle
    thread stack shadow poisoned.
    
    If a CPU returns to the kernel via a different path (e.g. a cold
    entry), then depending on stack frame layout subsequent calls to
    instrumented functions may use regions of the stack with stale poison,
    resulting in (spurious) KASAN splats to the console.
    
    Contemporary GCCs always add stack shadow poisoning when ASAN is
    enabled, even when asked to not instrument a function [1], so we can't
    simply annotate functions on the critical path to avoid poisoning.
    
    Instead, this series explicitly removes any stale poison before it can
    be hit.  In the common hotplug case we clear the entire stack shadow in
    common code, before a CPU is brought online.
    
    On architectures which perform a cold return as part of cpu idle may
    retain an architecture-specific amount of stack contents.  To retain the
    poison for this retained context, the arch code must call the core KASAN
    code, passing a "watermark" stack pointer value beyond which shadow will
    be cleared.  Architectures which don't perform a cold return as part of
    idle do not need any additional code.
    
    This patch (of 3):
    
    Functions which the compiler has instrumented for KASAN place poison on
    the stack shadow upon entry and remove this poision prior to returning.
    
    In some cases (e.g.  hotplug and idle), CPUs may exit the kernel a number
    of levels deep in C code.  If there are any instrumented functions on this
    critical path, these will leave portions of the stack shadow poisoned.
    
    If a CPU returns to the kernel via a different path (e.g.  a cold entry),
    then depending on stack frame layout subsequent calls to instrumented
    functions may use regions of the stack with stale poison, resulting in
    (spurious) KASAN splats to the console.
    
    To avoid this, we must clear stale poison from the stack prior to
    instrumented functions being called.  This patch adds functions to the
    KASAN core for removing poison from (portions of) a task's stack.  These
    will be used by subsequent patches to avoid problems with hotplug and
    idle.
    
    Signed-off-by: Mark Rutland <mark.rutland@arm.com>
    Acked-by: Catalin Marinas <catalin.marinas@arm.com>
    Reviewed-by: Andrey Ryabinin <aryabinin@virtuozzo.com>
    Cc: Alexander Potapenko <glider@google.com>
    Cc: Lorenzo Pieralisi <lorenzo.pieralisi@arm.com>
    Cc: Will Deacon <will.deacon@arm.com>
    Cc: Ingo Molnar <mingo@kernel.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/include/linux/kasan.h b/include/linux/kasan.h
index 4b9f85c963d0..0fdc798e3ff7 100644
--- a/include/linux/kasan.h
+++ b/include/linux/kasan.h
@@ -1,6 +1,7 @@
 #ifndef _LINUX_KASAN_H
 #define _LINUX_KASAN_H
 
+#include <linux/sched.h>
 #include <linux/types.h>
 
 struct kmem_cache;
@@ -13,7 +14,6 @@ struct vm_struct;
 
 #include <asm/kasan.h>
 #include <asm/pgtable.h>
-#include <linux/sched.h>
 
 extern unsigned char kasan_zero_page[PAGE_SIZE];
 extern pte_t kasan_zero_pte[PTRS_PER_PTE];
@@ -43,6 +43,8 @@ static inline void kasan_disable_current(void)
 
 void kasan_unpoison_shadow(const void *address, size_t size);
 
+void kasan_unpoison_task_stack(struct task_struct *task);
+
 void kasan_alloc_pages(struct page *page, unsigned int order);
 void kasan_free_pages(struct page *page, unsigned int order);
 
@@ -66,6 +68,8 @@ void kasan_free_shadow(const struct vm_struct *vm);
 
 static inline void kasan_unpoison_shadow(const void *address, size_t size) {}
 
+static inline void kasan_unpoison_task_stack(struct task_struct *task) {}
+
 static inline void kasan_enable_current(void) {}
 static inline void kasan_disable_current(void) {}
 
diff --git a/mm/kasan/kasan.c b/mm/kasan/kasan.c
index bc0a8d8b8f42..1ad20ade8c91 100644
--- a/mm/kasan/kasan.c
+++ b/mm/kasan/kasan.c
@@ -20,6 +20,7 @@
 #include <linux/init.h>
 #include <linux/kernel.h>
 #include <linux/kmemleak.h>
+#include <linux/linkage.h>
 #include <linux/memblock.h>
 #include <linux/memory.h>
 #include <linux/mm.h>
@@ -60,6 +61,25 @@ void kasan_unpoison_shadow(const void *address, size_t size)
 	}
 }
 
+static void __kasan_unpoison_stack(struct task_struct *task, void *sp)
+{
+	void *base = task_stack_page(task);
+	size_t size = sp - base;
+
+	kasan_unpoison_shadow(base, size);
+}
+
+/* Unpoison the entire stack for a task. */
+void kasan_unpoison_task_stack(struct task_struct *task)
+{
+	__kasan_unpoison_stack(task, task_stack_page(task) + THREAD_SIZE);
+}
+
+/* Unpoison the stack for the current task beyond a watermark sp value. */
+asmlinkage void kasan_unpoison_remaining_stack(void *sp)
+{
+	__kasan_unpoison_stack(current, sp);
+}
 
 /*
  * All functions below always inlined so compiler could

