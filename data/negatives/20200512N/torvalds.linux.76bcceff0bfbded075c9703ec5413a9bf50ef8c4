commit 76bcceff0bfbded075c9703ec5413a9bf50ef8c4
Author: Mukesh Rathor <mukesh.rathor@oracle.com>
Date:   Fri Jan 3 09:48:08 2014 -0500

    xen/pvh/mmu: Use PV TLB instead of native.
    
    We also optimize one - the TLB flush. The native operation would
    needlessly IPI offline VCPUs causing extra wakeups. Using the
    Xen one avoids that and lets the hypervisor determine which
    VCPU needs the TLB flush.
    
    Signed-off-by: Mukesh Rathor <mukesh.rathor@oracle.com>
    Signed-off-by: Konrad Rzeszutek Wilk <konrad.wilk@oracle.com>

diff --git a/arch/x86/xen/mmu.c b/arch/x86/xen/mmu.c
index 490ddb354590..c1d406f35523 100644
--- a/arch/x86/xen/mmu.c
+++ b/arch/x86/xen/mmu.c
@@ -2222,6 +2222,15 @@ static const struct pv_mmu_ops xen_mmu_ops __initconst = {
 void __init xen_init_mmu_ops(void)
 {
 	x86_init.paging.pagetable_init = xen_pagetable_init;
+
+	/* Optimization - we can use the HVM one but it has no idea which
+	 * VCPUs are descheduled - which means that it will needlessly IPI
+	 * them. Xen knows so let it do the job.
+	 */
+	if (xen_feature(XENFEAT_auto_translated_physmap)) {
+		pv_mmu_ops.flush_tlb_others = xen_flush_tlb_others;
+		return;
+	}
 	pv_mmu_ops = xen_mmu_ops;
 
 	memset(dummy_mapping, 0xff, PAGE_SIZE);

